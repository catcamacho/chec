{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "from pandas import DataFrame\n",
    "\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode, JoinNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import DataSink, FreeSurferSource, SelectFiles\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "\n",
    "from nipype.interfaces.freesurfer.preprocess import MRIConvert\n",
    "from nipype.interfaces.freesurfer.model import Binarize\n",
    "from nipype.interfaces.freesurfer import FSCommand, MRIConvert, ReconAll\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std, MotionOutliers, Merge\n",
    "from nipype.interfaces.fsl.preprocess import MCFLIRT, SliceTimer, FLIRT\n",
    "from nipype.interfaces.fsl.maths import ApplyMask\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.interfaces.fsl.epi import ApplyTOPUP, TOPUP\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "from nipype.interfaces.nipy.preprocess import Trim\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# Set study variables\n",
    "analysis_home = '/home/camachocm2/Analysis/ChEC/fmri_proc'\n",
    "raw_dir = analysis_home + '/raw'\n",
    "preproc_dir = analysis_home + '/preproc'\n",
    "firstlevel_dir = analysis_home + '/subjectlevel'\n",
    "secondlevel_dir = analysis_home + '/grouplevel'\n",
    "workflow_dir = analysis_home + '/workflows'\n",
    "phase_encoding_file = analysis_home + '/misc/chec_encoding_file.txt'\n",
    "mni_template = analysis_home + '/template/MNI152_T1_3mm_brain.nii.gz'\n",
    "mni_brainmask = analysis_home + '/template/MNI152_T1_3mm_brain_mask.nii.gz'\n",
    "\n",
    "#subject_info = DataFrame.read_csv(analysis_home + '/../misc/subjs.csv')\n",
    "#subjects_list = subject_info['SubjID'].tolist()\n",
    "subjects_list = ['1000','1001','1002','1006','1007','1008','1011','1015','1016','1017']\n",
    "\n",
    "# FreeSurfer set up - change SUBJECTS_DIR \n",
    "fs_dir = '/moochie/Cat/Aggregate_anats/subjects_dir'\n",
    "FSCommand.set_default_subjects_dir(fs_dir)\n",
    "\n",
    "# data collection specs\n",
    "TR = 0.8 #in seconds\n",
    "num_slices = 40\n",
    "slice_direction = False #True = z direction, top to bottom\n",
    "interleaved = True\n",
    "echo_train_length = 0.068 # in seconds, loc (0x18,0x91) in the dcm header\n",
    "TEs = ['13','38','64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data handling Nodes\n",
    "\n",
    "# Select subjects list\n",
    "infosource = Node(IdentityInterface(fields=['subjid']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "# FreeSurferSource - Data grabber specific for FreeSurfer data\n",
    "fssource = Node(FreeSurferSource(subjects_dir=fs_dir),\n",
    "                run_without_submitting=True,\n",
    "                name='fssource')\n",
    "\n",
    "# Sink data\n",
    "substitutions = [('_subjid_', ''),\n",
    "                 ('_func_','')] #output file name substitutions\n",
    "datasink = Node(DataSink(base_directory = preproc_dir,\n",
    "                        container = preproc_dir,\n",
    "                        substitutions = substitutions), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fMRI data Reconstruction Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull files\n",
    "rawfile_template = {'folder': raw_dir + '/{subjid}/{func}'}\n",
    "recon_selectfiles = Node(SelectFiles(rawfile_template), name='recon_selectfiles')\n",
    "recon_selectfiles.iterables = [('func',['chec_movie_PA','corr_chec_1','corr_chec_2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reconstruction nodes\n",
    "\n",
    "def sort_dicoms(dicom_directory):    \n",
    "    from pydicom import dcmread\n",
    "    from pandas import DataFrame\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from glob import glob\n",
    "    from os.path import isdir\n",
    "    from os import makedirs\n",
    "    import shutil\n",
    "    \n",
    "    dicoms = glob(dicom_directory + '/MR.*')\n",
    "    dicoms = sorted(dicoms)\n",
    "     \n",
    "    for dicom in dicoms:\n",
    "        info = dcmread(dicom)\n",
    "        te = info[0x18,0x81].value\n",
    "        \n",
    "        if not isdir(dicom_directory + '/TE_%d' % te):\n",
    "                makedirs(dicom_directory + '/TE_%d' % te)\n",
    "\n",
    "        shutil.move(dicom, dicom_directory + '/TE_%d' % te)\n",
    "    \n",
    "    dicom_names = []\n",
    "    TE_folders = glob(dicom_directory + '/TE_*')\n",
    "    TE_folders = sorted(TE_folders)\n",
    "    for folder in TE_folders:\n",
    "        temp = glob(folder + '/MR*')\n",
    "        temp = sorted(temp)\n",
    "        dicom_names.append(temp[0])\n",
    "        \n",
    "    return(dicom_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull Dicom information\n",
    "dicom_info = Node(Function(input_names=['dicom_directory'],\n",
    "                           output_names=['dicom_names'],  \n",
    "                           function=sort_dicoms), \n",
    "                       name='main_dicom_info')\n",
    "\n",
    "# convert to niftis\n",
    "convert_to_niftis = MapNode(MRIConvert(out_file='func.nii.gz', \n",
    "                                       out_type='niigz'), \n",
    "                            name='convert_to_niftis', \n",
    "                            iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_flow = Workflow(name='recon_flow')\n",
    "recon_flow.connect([(infosource, recon_selectfiles,[('subjid','subjid')]), \n",
    "                    (recon_selectfiles, dicom_info,[('folder','dicom_directory')]), \n",
    "                    (dicom_info, convert_to_niftis,[('dicom_names','in_file')]),\n",
    "                    \n",
    "                    (convert_to_niftis, datasink, [('out_file','separated_niftis')])\n",
    "                   ])\n",
    "\n",
    "recon_flow.base_dir = workflow_dir\n",
    "recon_flow.write_graph(graph2use='flat')\n",
    "recon_flow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fMRI Data Preprocessing Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File handling nodes\n",
    "\n",
    "pes_template={'PE_vol': preproc_dir + '/separated_niftis/{subjid}/corr_{pe_dir}/_convert_to_niftis0/func.nii.gz'}\n",
    "pes_selectfiles = Node(SelectFiles(pes_template), name='pes_selectfiles')\n",
    "pes_selectfiles.iterables = ('pe_dir',['chec_1','chec_2'])\n",
    "\n",
    "funcs_template={'func': preproc_dir + '/separated_niftis/{subjid}/chec_movie_PA/_convert_to_{func_te}/func.nii.gz'}\n",
    "funcs_selectfiles = Node(SelectFiles(funcs_template), name='funcs_selectfiles')\n",
    "funcs_selectfiles.iterables = ('func_te',['niftis0','niftis1','niftis2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ME-ICA (Kundu, et al., 2011)\n",
    "def tedana_clean(TE_niftis, TEs):\n",
    "    from pandas import DataFrame\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from tedana.workflows import tedana_workflow\n",
    "    \n",
    "    files = tedana_workflow(TE_niftis, TEs)\n",
    "    \n",
    "    \n",
    "    return(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tedana.workflows import tedana_workflow\n",
    "from tedana import (decomposition, model, selection, utils)\n",
    "te1 = '/home/camachocm2/Analysis/ChEC/fmri_proc/preproc/unwarped_funcs/1003/_func_te_niftis0/func_unwarped.nii.gz'\n",
    "te2 = '/home/camachocm2/Analysis/ChEC/fmri_proc/preproc/unwarped_funcs/1003/_func_te_niftis1/func_unwarped.nii.gz'\n",
    "te3 = '/home/camachocm2/Analysis/ChEC/fmri_proc/preproc/unwarped_funcs/1003/_func_te_niftis2/func_unwarped.nii.gz'\n",
    "TEs = [13,38,64]\n",
    "TE_niftis = [te1,te2,te3]\n",
    "files = tedana_workflow(TE_niftis, TEs)\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unwarping and ME cleaning nodes\n",
    "\n",
    "# include only the first volume of each PE volume\n",
    "trim_PEs = Node(Trim(end_index=1),name='trim_PEs')\n",
    "\n",
    "# merge to 1 file for topup to calculate the fieldcoef\n",
    "merge_pes = JoinNode(Merge(dimension='t',\n",
    "                           merged_file='merged_pes.nii.gz'), \n",
    "                     name='merge_pes', \n",
    "                     joinsource='pes_selectfiles', \n",
    "                     joinfield='in_files')\n",
    "\n",
    "topup = Node(TOPUP(encoding_file=phase_encoding_file), name='topup')\n",
    "\n",
    "apply_topup = Node(ApplyTOPUP(in_index=[2], encoding_file=phase_encoding_file, \n",
    "                              method='jac', out_corrected='func_unwarped.nii.gz'), \n",
    "                   name='apply_topup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepreprocflow = Workflow(name='prepreprocflow')\n",
    "prepreprocflow.connect([(infosource,pes_selectfiles, [('subjid','subjid')]),\n",
    "                        (infosource,funcs_selectfiles, [('subjid','subjid')]),\n",
    "                        (pes_selectfiles, trim_PEs, [('PE_vol','in_file')]), \n",
    "                        (trim_PEs, merge_pes, [('out_file','in_files')]), \n",
    "                        (merge_pes, topup, [('merged_file','in_file')]),\n",
    "                        (topup, apply_topup, [('out_fieldcoef','in_topup_fieldcoef'), \n",
    "                                              ('out_movpar','in_topup_movpar')]),\n",
    "                        (funcs_selectfiles, apply_topup, [('func','in_files')]),\n",
    "                        (apply_topup, datasink, [('out_corrected','unwarped_funcs')])\n",
    "                       ])\n",
    "\n",
    "prepreprocflow.base_dir = workflow_dir\n",
    "prepreprocflow.write_graph(graph2use='flat')\n",
    "prepreprocflow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file handling\n",
    "preproc_template={'func': preproc_dir + '/unwarped_funcs/{subjid}/te_niftis1/func_unwarped.nii.gz'}\n",
    "preproc_selectfiles = Node(SelectFiles(preproc_template), name='preproc_selectfiles')\n",
    "\n",
    "fssource = Node(FreeSurferSource(subjects_dir=fs_dir),\n",
    "                run_without_submitting=True,\n",
    "                name='fssource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fsid_convert(subject_id):\n",
    "    fs_subject = 'C' + str(subject_id)\n",
    "    return(fs_subject)\n",
    "\n",
    "fsid = Node(Function(input_names=['subject_id'], \n",
    "                     output_names=['fs_subject'], \n",
    "                     function=fsid_convert), \n",
    "            name='fsid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fMRI Data processing nodes\n",
    "\n",
    "# reorient images to MNI space standard\n",
    "reorientFunc = Node(Reorient2Std(terminal_output='file'),\n",
    "                   name='reorientFunc')\n",
    "\n",
    "# perform slice time correction\n",
    "slicetime = Node(SliceTimer(index_dir=slice_direction,\n",
    "                           interleaved=interleaved,\n",
    "                           time_repetition=TR),\n",
    "                name='slicetime')\n",
    "\n",
    "# realignment using mcflirt\n",
    "realignmc = Node(MCFLIRT(save_plots=True),\n",
    "                name='realignmc')\n",
    "\n",
    "# Coregistration using flirt\n",
    "coregflt = Node(FLIRT(),\n",
    "               name='coregflt')\n",
    "coregflt2 = Node(FLIRT(apply_xfm=True, \n",
    "                       out_file='preproc_func.nii.gz'),\n",
    "                name='coregflt2')\n",
    "\n",
    "#unzip file before feeding into ART\n",
    "gunzip_mask = Node(Gunzip(), name='gunzip_mask')\n",
    "gunzip_func = Node(Gunzip(), name='gunzip_func')\n",
    "\n",
    "# Artifact detection for scrubbing/motion assessment\n",
    "art = Node(ArtifactDetect(mask_type='file',\n",
    "                          parameter_source='FSL',\n",
    "                          bound_by_brainmask=True,\n",
    "                          norm_threshold=1,\n",
    "                          zintensity_threshold=3,\n",
    "                          use_differences=[True, False]),\n",
    "           name='art')\n",
    "\n",
    "# Register to MNI template\n",
    "reg2mni = Node(FLIRT(reference=mni_template),\n",
    "               name='reg2mni')\n",
    "reg2mni2 = Node(FLIRT(apply_xfm=True, \n",
    "                      reference=mni_template,\n",
    "                      out_file='proc_func.nii.gz'),\n",
    "                name='reg2mni2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Anatomical processing\n",
    "# Convert skullstripped brain to nii, resample to 2mm^3\n",
    "resample = Node(MRIConvert(out_type='niigz',\n",
    "                          vox_size=(3,3,3)),\n",
    "               name='resample')\n",
    "\n",
    "# Reorient anat to MNI space\n",
    "reorientAnat = Node(Reorient2Std(terminal_output='file'),\n",
    "                   name='reorientAnat')\n",
    "\n",
    "# Create binary mask of resampled, skullstripped anat, dilate, and erode to fill gaps\n",
    "binarize = Node(Binarize(dilate=1,\n",
    "                        erode=1,\n",
    "                        invert=False,\n",
    "                        min=1,\n",
    "                        max=255),\n",
    "               name='binarize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data QC nodes\n",
    "def create_coreg_plot(epi,anat):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = os.path.abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "def check_mask_coverage(epi,brainmask):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    \n",
    "    trim = Trim()\n",
    "    trim.inputs.in_file = epi\n",
    "    trim.inputs.end_index = 1\n",
    "    trim.inputs.out_file = 'epi_vol1.nii.gz'\n",
    "    trim.run()\n",
    "    epi_vol = abspath('epi_vol1.nii.gz')\n",
    "    \n",
    "    maskcheck_filename='maskcheck.png'\n",
    "    display = plotting.plot_anat(epi_vol, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'brainmask coverage')\n",
    "    display.add_contours(brainmask,levels=[.5], colors='r')\n",
    "    display.savefig(maskcheck_filename)\n",
    "    display.close()\n",
    "    maskcheck_file = abspath(maskcheck_filename)\n",
    "\n",
    "    return(maskcheck_file)\n",
    "\n",
    "make_coreg_img = Node(name='make_coreg_img',\n",
    "                      interface=Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot))\n",
    "\n",
    "make_checkmask_img = Node(name='make_checkmask_img',\n",
    "                      interface=Function(input_names=['epi','brainmask'],\n",
    "                                         output_names=['maskcheck_file'],\n",
    "                                         function=check_mask_coverage))\n",
    "make_checkmask_img.inputs.brainmask=mni_brainmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180920-12:36:27,853 workflow INFO:\n",
      "\t Generated workflow graph: /home/camachocm2/Analysis/ChEC/fmri_proc/workflows/preprocflow/graph.png (graph2use=flat, simple_form=True).\n",
      "180920-12:36:27,880 workflow INFO:\n",
      "\t Workflow preprocflow settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "180920-12:36:28,5 workflow INFO:\n",
      "\t Running in parallel.\n",
      "180920-12:36:28,13 workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 20 jobs ready. Free memory (GB): 8.00/8.00, Free processors: 1/1.\n",
      "180920-12:36:28,103 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocflow.fsid\" in \"/home/camachocm2/Analysis/ChEC/fmri_proc/workflows/preprocflow/_subjid_1011/fsid\".\n",
      "180920-12:36:28,113 workflow INFO:\n",
      "\t [Node] Running \"fsid\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "180920-12:36:28,121 workflow INFO:\n",
      "\t [Node] Finished \"preprocflow.fsid\".\n",
      "180920-12:36:30,15 workflow INFO:\n",
      "\t [Job 0] Completed (preprocflow.fsid).\n",
      "180920-12:36:30,22 workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 20 jobs ready. Free memory (GB): 8.00/8.00, Free processors: 1/1.\n",
      "180920-12:36:30,120 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocflow.fssource\" in \"/home/camachocm2/Analysis/ChEC/fmri_proc/workflows/preprocflow/_subjid_1011/fssource\".\n",
      "180920-12:36:30,125 workflow INFO:\n",
      "\t [Node] Running \"fssource\" (\"nipype.interfaces.io.FreeSurferSource\")\n",
      "180920-12:36:30,136 workflow INFO:\n",
      "\t [Node] Finished \"preprocflow.fssource\".\n",
      "180920-12:36:30,137 workflow INFO:\n",
      "\t [Job 1] Completed (preprocflow.fssource).\n",
      "180920-12:36:30,224 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocflow.fsid\" in \"/home/camachocm2/Analysis/ChEC/fmri_proc/workflows/preprocflow/_subjid_1015/fsid\".\n",
      "180920-12:36:30,231 workflow INFO:\n",
      "\t [Node] Running \"fsid\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "180920-12:36:30,237 workflow INFO:\n",
      "\t [Node] Finished \"preprocflow.fsid\".\n",
      "180920-12:36:32,18 workflow INFO:\n",
      "\t [Job 6] Completed (preprocflow.fsid).\n",
      "180920-12:36:32,24 workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 20 jobs ready. Free memory (GB): 8.00/8.00, Free processors: 1/1.\n",
      "180920-12:36:32,127 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocflow.resample\" in \"/home/camachocm2/Analysis/ChEC/fmri_proc/workflows/preprocflow/_subjid_1011/resample\".\n",
      "180920-12:36:32,139 workflow WARNING:\n",
      "\t [Node] Error on \"preprocflow.resample\" (/home/camachocm2/Analysis/ChEC/fmri_proc/workflows/preprocflow/_subjid_1011/resample)\n",
      "180920-12:36:34,22 workflow ERROR:\n",
      "\t Node resample.a6 failed to run on host myelin.\n",
      "180920-12:36:34,24 workflow ERROR:\n",
      "\t Saving crash info to /home/camachocm2/Analysis/ChEC/chec/fmri_network_models/crash-20180920-123634-camachocm2-resample.a6-64936359-6e1a-49c3-aef5-79a26db77ab3.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/nipype/pipeline/plugins/multiproc.py\", line 68, in run_node\n",
      "    result['result'] = node.run(updatehash=updatehash)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/nipype/pipeline/engine/nodes.py\", line 479, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/nipype/pipeline/engine/nodes.py\", line 563, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/nipype/pipeline/engine/nodes.py\", line 630, in _run_command\n",
      "    cmd = self._interface.cmdline\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/nipype/interfaces/base/core.py\", line 935, in cmdline\n",
      "    self._check_mandatory_inputs()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/nipype/interfaces/base/core.py\", line 389, in _check_mandatory_inputs\n",
      "    raise ValueError(msg)\n",
      "ValueError: MRIConvert requires a value for input 'in_file'. For a list of required inputs, see MRIConvert.help()\n",
      "\n",
      "180920-12:36:34,31 workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 19 jobs ready. Free memory (GB): 8.00/8.00, Free processors: 1/1.\n",
      "180920-12:36:34,138 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocflow.fssource\" in \"/home/camachocm2/Analysis/ChEC/fmri_proc/workflows/preprocflow/_subjid_1015/fssource\".\n",
      "180920-12:36:34,142 workflow INFO:\n",
      "\t [Node] Running \"fssource\" (\"nipype.interfaces.io.FreeSurferSource\")\n",
      "180920-12:36:34,153 workflow INFO:\n",
      "\t [Node] Finished \"preprocflow.fssource\".\n",
      "180920-12:36:34,154 workflow INFO:\n",
      "\t [Job 7] Completed (preprocflow.fssource).\n",
      "180920-12:36:34,296 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocflow.fsid\" in \"/home/camachocm2/Analysis/ChEC/fmri_proc/workflows/preprocflow/_subjid_1000/fsid\".\n",
      "180920-12:36:34,303 workflow INFO:\n",
      "\t [Node] Running \"fsid\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "180920-12:36:34,311 workflow INFO:\n",
      "\t [Node] Finished \"preprocflow.fsid\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process NonDaemonPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1cc2905b77ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mpreprocflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkflow_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mpreprocflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph2use\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mpreprocflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MultiProc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n_procs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'memory_gb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'write_provenance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nipype/pipeline/plugins/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0msleep_til\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpoll_sleep_secs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msleep_til\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_node_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "preprocflow = Workflow(name='preprocflow')\n",
    "\n",
    "preprocflow.connect([(infosource, preproc_selectfiles, [('subjid','subjid')]),\n",
    "                     (preproc_selectfiles,reorientFunc, [('func','in_file')]),\n",
    "                     (infosource, fsid, [('subjid','subject_id')]),\n",
    "                     (fsid, fssource, [('fs_subject','subject_id')]),\n",
    "                     (fssource, resample, [('brainmask','in_file')]),\n",
    "                     (resample, reorientAnat, [('out_file','in_file')]),\n",
    "                     (reorientAnat, binarize, [('out_file','in_file')]),\n",
    "                     (reorientFunc, slicetime, [('out_file','in_file')]),\n",
    "                     (slicetime, realignmc, [('slice_time_corrected_file','in_file')]),\n",
    "                     (reorientAnat, coregflt, [('out_file','reference')]),\n",
    "                     (realignmc, coregflt, [('out_file','in_file')]),\n",
    "                     (realignmc, coregflt2, [('out_file','in_file')]),\n",
    "                     (coregflt, coregflt2, [('out_matrix_file','in_matrix_file')]),\n",
    "                     (reorientAnat, coregflt2, [('out_file','reference')]),              \n",
    "                     (coregflt, reg2mni, [('out_file','in_file')]),\n",
    "                     (coregflt2, reg2mni2, [('out_file','in_file')]),\n",
    "                     (reg2mni, reg2mni2, [('out_matrix_file','in_matrix_file')]),                \n",
    "                     \n",
    "                     (binarize, gunzip_mask,[('binary_file','in_file')]), \n",
    "                     (gunzip_mask, art, [('out_file','mask_file')]),\n",
    "                     (coregflt2, gunzip_func, [('out_file','in_file')]),\n",
    "                     (gunzip_func, art, [('out_file','realigned_files')]),\n",
    "                     (realignmc, art, [('par_file','realignment_parameters')]),\n",
    "                     (coregflt, make_coreg_img, [('out_file','epi')]),\n",
    "                     (reorientAnat, make_coreg_img, [('out_file','anat')]),\n",
    "                     (reg2mni2, make_checkmask_img, [('out_file','epi')]),\n",
    "                     \n",
    "                     (reg2mni, datasink, [('out_file','reoriented_anat')]),\n",
    "                     (make_checkmask_img, datasink, [('maskcheck_file','checkmask_image')]),\n",
    "                     (make_coreg_img, datasink, [('coreg_file','coreg_image')]),\n",
    "                     (reg2mni2, datasink, [('out_file','mnireg_func')]),\n",
    "                     (art, datasink, [('plot_files','art_plot')]), \n",
    "                     (art, datasink, [('outlier_files','art_outliers')]),\n",
    "                     (realignmc, datasink, [('par_file','mcflirt_displacement')])\n",
    "                    ])\n",
    "preprocflow.base_dir = workflow_dir\n",
    "preprocflow.write_graph(graph2use='flat')\n",
    "preprocflow.run('MultiProc', plugin_args={'n_procs': 1, 'memory_gb':8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
