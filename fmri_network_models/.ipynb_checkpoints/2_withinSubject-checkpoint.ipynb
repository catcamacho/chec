{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "from os.path import join\n",
    "from pandas import DataFrame\n",
    "\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.base import Bunch\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.interfaces.fsl.maths import TemporalFilter\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# Set study variables\n",
    "analysis_home = '/home/camachocm2/Analysis/ChEC/fmri_proc'\n",
    "raw_dir = analysis_home + '/raw'\n",
    "preproc_dir = analysis_home + '/preproc'\n",
    "firstlevel_dir = analysis_home + '/subjectlevel'\n",
    "secondlevel_dir = analysis_home + '/grouplevel'\n",
    "workflow_dir = analysis_home + '/workflows'\n",
    "timing_file = '/home/camachocm2/Analysis/ChEC/misc/affect.txt'\n",
    "#subject_info = DataFrame.read_csv(analysis_home + '/../misc/subjs.csv')\n",
    "#subjects_list = subject_info['SubjID'].tolist()\n",
    "subjects_list = ['pilot002']\n",
    "\n",
    "# data collection specs\n",
    "TR = 0.8 #in seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subjects list\n",
    "infosource = Node(IdentityInterface(fields=['subjid']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "# Pull files\n",
    "file_template = {'preproc_func': preproc_dir + '/coreg_func/{subjid}/preproc_func.nii.gz', \n",
    "                 'motion': preproc_dir + '/displacement/{subjid}/fd.txt', \n",
    "                 'outliers': preproc_dir + '/art_outliers/{subjid}/art.preproc_func_outliers.txt'}\n",
    "\n",
    "selectfiles = Node(SelectFiles(file_template), name='selectfiles')\n",
    "\n",
    "# Sink data of interest (mostly for QC)\n",
    "substitutions = [('_subjid_', '')] #output file name substitutions\n",
    "datasink = Node(DataSink(base_directory = firstlevel_dir,\n",
    "                        container = firstlevel_dir,\n",
    "                        substitutions = substitutions), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Timing handling nodes\n",
    "def affectiveTiming(timing_file, motion, outliers):\n",
    "    from nipype import logging, config\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from numpy import genfromtxt, zeros, column_stack, savetxt\n",
    "    from os.path import abspath \n",
    "    \n",
    "    motion = genfromtxt(motion, delimiter=None, dtype=None, skip_header=0)\n",
    "    timing = genfromtxt(timing_file, delimiter=None, dtype=None, skip_header=0)\n",
    "    censor_vol_list = genfromtxt(outliers, delimiter=None, dtype=None, skip_header=0)\n",
    "    \n",
    "    try:\n",
    "        c = censor_vol_list.size\n",
    "    except:\n",
    "        c = 0\n",
    "    \n",
    "    d=len(motion)\n",
    "\n",
    "    if c > 1:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        for t in range(c):\n",
    "            scrubbing[censor_vol_list[t],t] = 1\n",
    "        regres_matrix = column_stack((timing, motion, scrubbing))\n",
    "    elif c == 1:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        scrubbing[censor_vol_list] = 1\n",
    "        regres_matrix = column_stack((timing, motion, scrubbing))\n",
    "    else:\n",
    "        regres_matrix = column_stack((timing, motion))\n",
    "    \n",
    "    design_file_name = 'matrix.txt'\n",
    "    savetxt(design_file_name, regres_matrix)\n",
    "    design_file = abspath(design_file_name)\n",
    "    \n",
    "    return(design_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "affective_timing = Node(Function(input_names=['timing_file', 'motion', 'outliers'],\n",
    "                                 output_names=['design_file'],\n",
    "                                 function=affectiveTiming), \n",
    "                        name='affective_timing')\n",
    "affective_timing.inputs.timing_file = timing_file\n",
    "\n",
    "#high pass filter\n",
    "high_pass = Node(TemporalFilter(highpass_sigma=128/TR), \n",
    "                 name='high_pass')\n",
    "\n",
    "#run the GLM\n",
    "estmodel = Node(GLM(dat_norm = True,\n",
    "                    out_file = 'betas.nii.gz', \n",
    "                    out_cope='cope.nii.gz',\n",
    "                    out_t_name = 'tstat.nii.gz'), \n",
    "                name= 'estmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180510-14:46:09,242 workflow INFO:\n",
      "\t Generated workflow graph: /home/camachocm2/Analysis/ChEC/fmri_proc/workflows/L1workflow/graph.png (graph2use=flat, simple_form=True).\n",
      "180510-14:46:09,273 workflow INFO:\n",
      "\t Workflow L1workflow settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "180510-14:46:09,288 workflow INFO:\n",
      "\t Running in parallel.\n",
      "180510-14:46:09,292 workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 10.00/10.00, Free processors: 4/4.\n",
      "180510-14:46:09,366 workflow INFO:\n",
      "\t [Node] Setting-up \"L1workflow.selectfiles\" in \"/home/camachocm2/Analysis/ChEC/fmri_proc/workflows/L1workflow/_subjid_pilot002/selectfiles\".\n",
      "180510-14:46:09,378 workflow INFO:\n",
      "\t [Node] Running \"selectfiles\" (\"nipype.interfaces.io.SelectFiles\")\n",
      "180510-14:46:09,386 workflow INFO:\n",
      "\t [Node] Finished \"L1workflow.selectfiles\".\n",
      "180510-14:46:11,294 workflow INFO:\n",
      "\t [Job 0] Completed (L1workflow.selectfiles).\n",
      "180510-14:46:11,299 workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 10.00/10.00, Free processors: 4/4.\n",
      "180510-14:46:11,365 workflow INFO:\n",
      "\t [Job 1] Cached (L1workflow.affective_timing).\n",
      "180510-14:46:13,365 workflow INFO:\n",
      "\t [Node] Setting-up \"L1workflow.estmodel\" in \"/home/camachocm2/Analysis/ChEC/fmri_proc/workflows/L1workflow/_subjid_pilot002/estmodel\".\n",
      "180510-14:46:13,379 workflow INFO:\n",
      "\t [Node] Running \"estmodel\" (\"nipype.interfaces.fsl.model.GLM\"), a CommandLine Interface with command:\n",
      "fsl_glm -i /home/camachocm2/Analysis/ChEC/fmri_proc/preproc/coreg_func/pilot002/preproc_func.nii.gz -d /home/camachocm2/Analysis/ChEC/fmri_proc/workflows/L1workflow/_subjid_pilot002/affective_timing/matrix.txt -o betas.nii.gz --dat_norm --out_cope=cope.nii.gz --out_t=tstat.nii.gz\n",
      "180510-14:46:15,299 workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 9.80/10.00, Free processors: 3/4.\n",
      "                     Currently running:\n",
      "                       * L1workflow.estmodel\n",
      "180510-15:25:03,56 root ERROR:\n",
      "\t Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process NonDaemonPoolWorker-11:\n",
      "Process NonDaemonPoolWorker-8:\n",
      "Process NonDaemonPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    util._exit_function()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-13ec03f60dd1>\", line 15, in <module>\n",
      "    L1workflow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':10})\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/nipype/pipeline/engine/workflows.py\", line 595, in run\n",
      "    runner.run(execgraph, updatehash=updatehash, config=self.config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/nipype/pipeline/plugins/base.py\", line 195, in run\n",
      "    sleep(max(0, sleep_til - time()))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 708, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "Process NonDaemonPoolWorker-16:\n",
      "Process NonDaemonPoolWorker-14:\n",
      "Process NonDaemonPoolWorker-12:\n",
      "Process NonDaemonPoolWorker-15:\n",
      "Process NonDaemonPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process NonDaemonPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "L1workflow = Workflow(name='L1workflow')\n",
    "L1workflow.connect([(infosource,selectfiles,[('subjid','subjid')]),\n",
    "                    (selectfiles, affective_timing,[('motion','motion')]),\n",
    "                    (selectfiles, affective_timing,[('outliers','outliers')]),\n",
    "                    (affective_timing,estmodel,[('design_file','design')]),\n",
    "                    (selectfiles,estmodel,[('preproc_func','in_file')]),\n",
    "                    \n",
    "                    (affective_timing, datasink, [('design_file','design_tnp')]),\n",
    "                    (estmodel, datasink, [('out_cope','copes')]),\n",
    "                    (estmodel, datasink, [('out_t','tstats')]),\n",
    "                    (estmodel, datasink, [('out_file','betas')])\n",
    "                   ])\n",
    "L1workflow.base_dir = join(workflow_dir)\n",
    "L1workflow.write_graph(graph2use='flat')\n",
    "L1workflow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
