{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "from os import listdir, makedirs\n",
    "from os.path import isdir\n",
    "from pandas import DataFrame, Series, read_csv\n",
    "\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode, JoinNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import DataSink, FreeSurferSource, SelectFiles\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "\n",
    "from nipype.interfaces.freesurfer.preprocess import MRIConvert\n",
    "from nipype.interfaces.freesurfer.model import Binarize\n",
    "from nipype.interfaces.freesurfer import FSCommand, MRIConvert, ReconAll\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std, MotionOutliers, Merge\n",
    "from nipype.interfaces.fsl.preprocess import MCFLIRT, SliceTimer, FLIRT\n",
    "from nipype.interfaces.fsl.maths import ApplyMask\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.interfaces.fsl.epi import ApplyTOPUP, TOPUP\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "from nipype.interfaces.nipy.preprocess import Trim\n",
    "from nipype.interfaces.afni.preprocess import Bandpass\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# Set study variables\n",
    "analysis_home = '/data/perlman/moochie/user_data/CamachoCat/ChEC/fmri_proc'\n",
    "raw_dir =  '/data/perlman/moochie/study_data/ChEC/MRI_data'\n",
    "preproc_dir = analysis_home + '/preproc'\n",
    "firstlevel_dir = analysis_home + '/subjectlevel'\n",
    "secondlevel_dir = analysis_home + '/grouplevel'\n",
    "workflow_dir = analysis_home + '/workflows'\n",
    "phase_encoding_file = analysis_home + '/misc/chec_encoding_file.txt'\n",
    "\n",
    "templates_dir = '/data/perlman/moochie/user_data/CamachoCat/Aggregate_anats/templates'\n",
    "template_brain = templates_dir + '/lcbd_template_2mm_brain.nii.gz'\n",
    "template_mask = templates_dir + '/lcbd_template_2mm_mask.nii.gz'\n",
    "template_mask_dilated = templates_dir + '/lcbd_template_2mm_maskD1.nii.gz'\n",
    "gm_mask = templates_dir + '/lcbd_template_2mm_gm.nii.gz'\n",
    "wmcsf_mask = templates_dir + '/lcbd_template_2mm_wmcsf.nii.gz'\n",
    "\n",
    "subject_info = read_csv(analysis_home + '/misc/subjectinfo.csv',index_col=None)\n",
    "subjects_list = subject_info['SubjID'].tolist()\n",
    "#subjects_list = ['1032']\n",
    "\n",
    "# FreeSurfer set up - change SUBJECTS_DIR \n",
    "fs_dir = '/data/perlman/moochie/user_data/CamachoCat/Aggregate_anats/subjects_dir'\n",
    "FSCommand.set_default_subjects_dir(fs_dir)\n",
    "\n",
    "# data collection specs\n",
    "TR = 0.8 #in seconds\n",
    "num_slices = 40\n",
    "slice_direction = False #True = z direction, top to bottom\n",
    "interleaved = True\n",
    "slice_timing = analysis_home + '/misc/slice_timing.txt'\n",
    "echo_train_length = 0.051 # in seconds, loc (0x18,0x91) in the dcm header\n",
    "TEs = [13.2,38.76,64.32] #in milliseconds\n",
    "\n",
    "highpass_freq = 0.008\n",
    "lowpass_freq = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data handling Nodes\n",
    "\n",
    "# Select subjects list\n",
    "infosource = Node(IdentityInterface(fields=['subjid']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "# FreeSurferSource - Data grabber specific for FreeSurfer data\n",
    "fssource = Node(FreeSurferSource(subjects_dir=fs_dir),\n",
    "                run_without_submitting=True,\n",
    "                name='fssource')\n",
    "\n",
    "# Sink data\n",
    "substitutions = [('_subjid_', ''),\n",
    "                 ('_func_','')] #output file name substitutions\n",
    "datasink = Node(DataSink(base_directory = preproc_dir,\n",
    "                        container = preproc_dir,\n",
    "                        substitutions = substitutions), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## fMRI Data Prep\n",
    "This workflow carries out the following processing steps:\n",
    "1. Slice-time correction\n",
    "2. Realignment (motion parameters derived from this step)\n",
    "3. Multi-echo denoising\n",
    "4. Distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## File handling nodes\n",
    "\n",
    "pes_template={'PE_vol': raw_dir + '/sub-{subjid}/fmap/sub-{subjid}_task-AHKJ-{pe_dir}_bold.nii.gz'}\n",
    "pes_selectfiles = Node(SelectFiles(pes_template), name='pes_selectfiles')\n",
    "pes_selectfiles.iterables = ('pe_dir',['1','2'])\n",
    "\n",
    "echo2_template={'echo2': raw_dir + '/sub-{subjid}/func/sub-{subjid}_task-AHKJ-ep2-e2_bold.nii.gz'}\n",
    "echo2_selectfiles = Node(SelectFiles(echo2_template), name='echo2_selectfiles')\n",
    "\n",
    "funcs_template={'func': raw_dir + '/sub-{subjid}/func/sub-{subjid}_task-AHKJ-ep2-{func_te}_bold.nii.gz'}\n",
    "funcs_selectfiles = Node(SelectFiles(funcs_template), name='funcs_selectfiles')\n",
    "funcs_selectfiles.iterables = ('func_te',['e1','e2','e3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Apply ME-ICA (Kundu, et al., 2011)\n",
    "def tedana_clean(TE_niftis, TEs):\n",
    "    from pandas import DataFrame\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import abspath\n",
    "    \n",
    "    from tedana.workflows import tedana_workflow\n",
    "    \n",
    "    files = tedana_workflow(TE_niftis, TEs)\n",
    "    denoised_func = abspath('dn_ts_OC.nii')\n",
    "    \n",
    "    return(denoised_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# perform slice time correction\n",
    "slicetime = Node(SliceTimer(index_dir=slice_direction,\n",
    "                            custom_timings=slice_timing,\n",
    "                            time_repetition=TR),\n",
    "                    name='slicetime')\n",
    "\n",
    "# realignment using mcflirt\n",
    "realignmc = Node(MCFLIRT(save_plots=True, save_mats=True),\n",
    "                name='realignmc')\n",
    "\n",
    "# apply realignment to all echoes\n",
    "applyrealign = Node(MCFLIRT(save_plots=True),name='applyrealign')\n",
    "\n",
    "## Unwarping and ME cleaning nodes\n",
    "# ME denoising using Tedana\n",
    "me_denoise = JoinNode(Function(input_names=['TE_niftis','TEs'],\n",
    "                               output_names=['denoised_func'],\n",
    "                               function=tedana_clean), \n",
    "                      name='me_denoise',joinsource='funcs_selectfiles',joinfield='TE_niftis')\n",
    "me_denoise.inputs.TEs = TEs\n",
    "\n",
    "# include only the first volume of each PE volume\n",
    "trim_PEs = Node(Trim(end_index=1),name='trim_PEs')\n",
    "\n",
    "# merge to 1 file for topup to calculate the fieldcoef\n",
    "merge_pes = JoinNode(Merge(dimension='t',\n",
    "                           merged_file='merged_pes.nii.gz'), \n",
    "                     name='merge_pes', \n",
    "                     joinsource='pes_selectfiles', \n",
    "                     joinfield='in_files')\n",
    "\n",
    "topup = Node(TOPUP(encoding_file=phase_encoding_file), name='topup')\n",
    "\n",
    "apply_topup = Node(ApplyTOPUP(in_index=[2], encoding_file=phase_encoding_file, \n",
    "                              method='jac', out_corrected='func_unwarped.nii.gz'), \n",
    "                   name='apply_topup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prepreprocflow = Workflow(name='prepreprocflow')\n",
    "prepreprocflow.connect([(infosource,pes_selectfiles, [('subjid','subjid')]),\n",
    "                        (infosource,funcs_selectfiles, [('subjid','subjid')]),\n",
    "                        (funcs_selectfiles, slicetime,[('func','in_file')]),\n",
    "                        (slicetime, applyrealign, [('slice_time_corrected_file','in_file')]),\n",
    "                        (applyrealign, me_denoise, [('out_file','TE_niftis')]),\n",
    "                        (pes_selectfiles, trim_PEs, [('PE_vol','in_file')]), \n",
    "                        (trim_PEs, merge_pes, [('out_file','in_files')]), \n",
    "                        (merge_pes, topup, [('merged_file','in_file')]),\n",
    "                        (topup, apply_topup, [('out_fieldcoef','in_topup_fieldcoef'), \n",
    "                                              ('out_movpar','in_topup_movpar')]),\n",
    "                        (me_denoise, apply_topup, [('denoised_func','in_files')]),\n",
    "                        \n",
    "                        (applyrealign, datasink, [('par_file','motion_file')]),\n",
    "                        (apply_topup, datasink, [('out_corrected','unwarped_funcs')])\n",
    "                       ])\n",
    "\n",
    "prepreprocflow.base_dir = workflow_dir\n",
    "#prepreprocflow.write_graph(graph2use='flat')\n",
    "prepreprocflow.run('MultiProc', plugin_args={'n_procs': 8, 'memory_gb':40})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration to common space and denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file handling\n",
    "preproc_template={'func': preproc_dir + '/unwarped_funcs/{subjid}/func_unwarped.nii.gz',\n",
    "                  'motion': preproc_dir + '/motion_file/{subjid}/te_e2/sub-{subjid}_task-AHKJ-ep2-e2_bold_st_mcf.nii.gz.par',\n",
    "                  'orig_file': raw_dir + '/sub-{subjid}/func/sub-{subjid}_task-AHKJ-ep2-e2_bold.nii.gz'}\n",
    "preproc_selectfiles = Node(SelectFiles(preproc_template), name='preproc_selectfiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fsid_convert(subject_id):\n",
    "    fs_subject = 'C' + str(subject_id)\n",
    "    return(fs_subject)\n",
    "\n",
    "fsid = Node(Function(input_names=['subject_id'], \n",
    "                     output_names=['fs_subject'], \n",
    "                     function=fsid_convert), \n",
    "            name='fsid')\n",
    "\n",
    "def makenoisemat(motion_file,wmcsf_nifti):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import abspath\n",
    "    import numpy as np\n",
    "    from nibabel import load\n",
    "\n",
    "    motion_params = np.loadtxt(motion_file, dtype=float)\n",
    "    trs = motion_params.shape[0]\n",
    "    params = motion_params.shape[1]\n",
    "    derivatives = np.gradient(motion_params, axis=0)\n",
    "    leadlagderivs = np.zeros((trs,params*6))\n",
    "    derivativessq = derivatives**2\n",
    "    leadlagderivssq = np.zeros((trs,params*6))\n",
    "\n",
    "    for i in range(0,params):\n",
    "        for j in range(0,6):\n",
    "            leadlagderivs[:,j+params*i] =  np.roll(derivatives[:,i],shift=j, axis=0)\n",
    "            leadlagderivs[:j,j+params*i] = 0\n",
    "\n",
    "    for i in range(0,params):\n",
    "        for j in range(0,6):\n",
    "            leadlagderivssq[:,j+params*i] =  np.roll(derivativessq[:,i],shift=j, axis=0)\n",
    "            leadlagderivssq[:j,j+params*i] = 0\n",
    "    \n",
    "    img = load(wmcsf_nifti)\n",
    "    data = img.get_fdata()\n",
    "    wmcsf = np.mean(data,axis=(0,1,2))\n",
    "    noise = np.hstack(leadlagderivs, leadlagderivssq, wmcsf,np.ones((1605,1)))\n",
    "    np.savetxt('noisemat.txt',noise)\n",
    "    noise_mat = abspath('noisemat.txt')\n",
    "    \n",
    "    return(noise_mat)\n",
    "\n",
    "def voxelwise_glm(func,shared_noise_file,mask):\n",
    "    from os.path import abspath\n",
    "    import numpy as np\n",
    "    from numpy.linalg import pinv\n",
    "    from pandas import read_csv, Series\n",
    "    from nilearn.masking import apply_mask, unmask\n",
    "\n",
    "    # import data into an array that is timepoints (rows) by voxel number (columns)\n",
    "    noise_mat = np.loadtxt(shared_noise_file)\n",
    "    func_data = apply_mask(func, mask)\n",
    "    coefficients = np.zeros((noise_mat.shape[1],func_data.shape[1]))\n",
    "    resid_data = np.zeros(func_data.shape)\n",
    "\n",
    "    # perform voxel-wise matrix inversion\n",
    "    for x in range(0,func_data.shape[1]):\n",
    "        y = func_data[:,x]\n",
    "        inv_mat = pinv(noise_mat)\n",
    "        coefficients[:,x] = np.dot(inv_mat,y)\n",
    "        yhat=sum(np.transpose(coefficients[:,x])*noise_mat,axis=1)\n",
    "        resid_data[:,x] = y - np.transpose(yhat)\n",
    "\n",
    "    resid_image = unmask(resid_data, mask)\n",
    "    resid_image.to_filename('residuals.nii.gz')\n",
    "\n",
    "    coeff_image = unmask(coefficients, mask)\n",
    "    coeff_image.to_filename('weights.nii.gz')\n",
    "\n",
    "    weights = abspath('weights.nii.gz')\n",
    "    residuals = abspath('residuals.nii.gz')\n",
    "\n",
    "    return(weights, residuals)\n",
    "\n",
    "def censor_interp(in_file,mask,fd_file,dvars_file):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn.masking import apply_mask, unmask\n",
    "    import numpy as np\n",
    "    from pandas import DataFrame\n",
    "    from scipy.stats import zscore\n",
    "\n",
    "    func_data = apply_mask(in_file,mask)\n",
    "    fd = np.loadtxt(fd_file, dtype=int)\n",
    "    dvars = np.loadtxt(dvars_file, dtype=int)\n",
    "    dvarsz = zscore(dvars)\n",
    "    \n",
    "    vols_to_censor = np.zeros(fd.shape)\n",
    "    vols_to_censor[fd>0.25] = 1\n",
    "    vols_to_censor[dvarsz>2] = 1\n",
    "\n",
    "    func_data[vols_to_censor==1] = np.nan\n",
    "    # put func data into pandas dataframe to make interpolation easier/faster\n",
    "    func_data_df = DataFrame(func_data)\n",
    "    interp_func_df = func_data_df.interpolate(limit_direction='both')\n",
    "\n",
    "    interp_func = interp_func_df.to_numpy()\n",
    "    interp_func_img = unmask(interp_func, mask)\n",
    "    interp_func_img.to_filename('interpolated_func.nii.gz')\n",
    "    interpolated_func = abspath('interpolated_func.nii.gz')\n",
    "    \n",
    "    np.savetxt('volstocensor.txt',vols_to_censor)\n",
    "    censored_vols_file = abspath('volstocensor.txt')\n",
    "    \n",
    "    return(interpolated_func, censored_vols_file)\n",
    "\n",
    "def nan_high_motion_trs(in_file, mask, vols_to_censor):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn.masking import apply_mask, unmask\n",
    "    import numpy as np\n",
    "    \n",
    "    vols_to_censor = np.loadtxt(vols_to_censor,dtype=int)\n",
    "    func_data = apply_mask(in_file,mask)\n",
    "    func_data[vols_to_censor==1] = np.nan\n",
    "    \n",
    "    lomo_image = unmask(func_data,mask)\n",
    "    lomo_image.to_filename('lomo_func.nii.gz')\n",
    "    out_file = abspath('lomo_func.nii.gz')\n",
    "    \n",
    "    return(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Anatomical processing\n",
    "# Convert skullstripped brain to nii, resample to 2mm^3\n",
    "resample = Node(MRIConvert(out_type='niigz',\n",
    "                          vox_size=(2,2,2)),\n",
    "               name='resample')\n",
    "\n",
    "# Reorient anat to MNI space\n",
    "reorientanat = Node(Reorient2Std(terminal_output='file'),\n",
    "                   name='reorientanat')\n",
    "\n",
    "## fMRI Data processing nodes\n",
    "# reorient images to MNI space standard\n",
    "reorientfunc = Node(Reorient2Std(terminal_output='file'),\n",
    "                   name='reorientfunc')\n",
    "\n",
    "# Coregistration using flirt\n",
    "coregflt = Node(FLIRT(),\n",
    "               name='coregflt')\n",
    "coregflt2 = Node(FLIRT(apply_xfm=True, \n",
    "                       out_file='preproc_func.nii.gz'),\n",
    "                name='coregflt2')\n",
    "\n",
    "# Register to sample template\n",
    "reg2mni = Node(FLIRT(reference=template_brain),\n",
    "               name='reg2mni')\n",
    "reg2mni2 = Node(FLIRT(apply_xfm=True, \n",
    "                      reference=template_brain,\n",
    "                      out_file='proc_func.nii.gz'),\n",
    "                name='reg2mni2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## motion and artifact denoising\n",
    "\n",
    "# compute DVARS\n",
    "calc_dvars = Node(MotionOutliers(metric='dvars',out_metric_values='dvars.txt',\n",
    "                                 out_metric_plot='dvars_plot.png'),name='calc_dvars')\n",
    "\n",
    "# compute FD\n",
    "calc_fd = Node(MotionOutliers(metric='fd',out_metric_values='fd.txt',\n",
    "                              out_metric_plot='fd_plot.png'),name='calc_fd')\n",
    "\n",
    "# create WM noise file\n",
    "mask_wmcsf = Node(ApplyMask(mask_file=wmcsf_mask), name='mask_wmcsf')\n",
    "\n",
    "# create Volterra series and compile noise mat\n",
    "prep_noise = Node(Function(input_names=['motion_file','wmcsf_nifti'], \n",
    "                           output_names=['noise_mat'],\n",
    "                           function=makenoisemat), \n",
    "                  name='prep_motion')\n",
    "\n",
    "# Denoise data\n",
    "denoise_func = Node(Function(input_names=['func','shared_noise_file','mask'], \n",
    "                             output_names=['weights','residuals'],\n",
    "                             function=voxelwise_glm),\n",
    "                       name='denoise_func')\n",
    "denoise_func.inputs.mask = template_mask_dilated\n",
    "\n",
    "# Censor and interpolate data\n",
    "censor_interpolate = Node(Function(input_names=['in_file','mask','fd_file','dvars_file'],\n",
    "                                   output_names=['interpolated_func','censored_vols_file'], \n",
    "                                   function=censor_interp), \n",
    "                          name='censor_interpolate')\n",
    "censor_interpolate.inputs.mask = template_gmmask\n",
    "\n",
    "# band pass filtering- all rates are in Hz (1/TR or samples/second)\n",
    "bandpass = Node(Bandpass(tr=TR, highpass=highpass_freq,\n",
    "                         lowpass=lowpass_freq, \n",
    "                         out_file='resids_filt.nii.gz', \n",
    "                         normalize=True), \n",
    "                name='bandpass')\n",
    "\n",
    "# NaN interpolated data\n",
    "nan_himo = Node(Function(input_names=['in_file','mask','vols_to_censor'], \n",
    "                          output_names=['out_file'], \n",
    "                          function=drop_high_motion_trs), \n",
    "                 name='nan_himo')\n",
    "nan_himo.inputs.mask = template_gmmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Data QC nodes\n",
    "motion_df_file = preproc_dir + '/motion_summary/motionSummary.csv'\n",
    "\n",
    "if isdir(preproc_dir + '/motion_summary')==False:\n",
    "    makedirs(preproc_dir + '/motion_summary')\n",
    "    motion_df = DataFrame(columns=['NumCensoredVols','percentCensored','secondsNotCensored','rawFD','censoredFD'])\n",
    "    motion_df.to_csv(motion_df_file)\n",
    "    \n",
    "def summarize_motion(motion_df_file, vols_to_censor, FD, TR,subject):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import dirname, basename\n",
    "    from numpy import asarray, mean, insert, zeros, sort\n",
    "    from pandas import DataFrame, Series, read_csv\n",
    "    \n",
    "    motion_df = read_csv(motion_df_file, index_col=0)\n",
    "    censvols = np.loadtxt(vols_to_censor, dtype=int)\n",
    "    fd = loadtxt(FD)\n",
    "    fd_censored = fd[censvols==0]\n",
    "    sec_not_censored = (1605-len(fd_censored))*TR\n",
    "\n",
    "    motion_df.loc[subject] = [len(censvols),len(censvols)/1605,sec_not_censored,np.mean(fd),np.mean(fd_censored)]\n",
    "    motion_df.to_csv(motion_df_file)\n",
    "    return()\n",
    "\n",
    "motion_summary = Node(Function(input_names=['motion_df_file','vols_to_censor','FD','TR'], \n",
    "                               output_names=[], \n",
    "                               function=summarize_motion), \n",
    "                      name='motion_summary')\n",
    "motion_summary.inputs.motion_df_file = motion_df_file\n",
    "motion_summary.inputs.TR = TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocflow = Workflow(name='preprocflow')\n",
    "\n",
    "preprocflow.connect([(infosource, preproc_selectfiles, [('subjid','subjid')]),\n",
    "                     (infosource, motion_summary,[('subjid','subject')]),\n",
    "                     (preproc_selectfiles,reorientfunc, [('func','in_file')]),\n",
    "                     (infosource, fsid, [('subjid','subject_id')]),\n",
    "                     (fsid, fssource, [('fs_subject','subject_id')]),\n",
    "                     (fssource, resample, [('brainmask','in_file')]),\n",
    "                     (resample, reorientanat, [('out_file','in_file')]),\n",
    "                     (reorientanat, coregflt, [('out_file','reference')]),\n",
    "                     (realignmc, coregflt, [('out_file','in_file')]),\n",
    "                     (realignmc, coregflt2, [('out_file','in_file')]),\n",
    "                     (coregflt, coregflt2, [('out_matrix_file','in_matrix_file')]),\n",
    "                     (reorientanat, coregflt2, [('out_file','reference')]),              \n",
    "                     (coregflt, reg2mni, [('out_file','in_file')]),\n",
    "                     (coregflt2, reg2mni2, [('out_file','in_file')]),\n",
    "                     (reg2mni, reg2mni2, [('out_matrix_file','in_matrix_file')]),                \n",
    "                     \n",
    "                     (preproc_selectfiles, calc_dvars, [('orig_file','in_file')]), \n",
    "                     (preproc_selectfiles, calc_fd, [('orig_file','in_file')]),\n",
    "                     (calc_dvars, censor_interpolate, [('out_metric_values','dvars_file')]),\n",
    "                     (calc_fd, censor_interpolate, [('out_metric_values','fd_file')]),\n",
    "                     (reg2mni2, mask_wmcsf, [('out_file','in_file')]),\n",
    "                     (mask_wmcsf, prep_noise, [('out_file','wmcsf_nifti')]),\n",
    "                     (prep_noise, denoise_func, [('noise_mat','shared_noise_file')]),\n",
    "                     (preproc_selectfiles, prep_noise, [('motion','motion_file')]),\n",
    "                     \n",
    "                     (binarize, gunzip_mask,[('binary_file','in_file')]), \n",
    "                     (coregflt2, gunzip_func, [('out_file','in_file')]),\n",
    "                     (censor_interpolate, motion_summary, [('censored_vols_file','vols_to_censor')]),\n",
    "                     (select_sub_files, censor_interpolate, [('motion','motion')]),\n",
    "                      \n",
    "                     (preproc_selectfiles, drop_himo,[('motion','motion')]),\n",
    "                     (preproc_selectfiles, denoise_func, [('func','func')]),\n",
    "                     (denoise_func,censor_interpolate,[('residuals','in_file')]),\n",
    "                     (censor_interpolate, bandpass, [('interpolated_func','in_file')]),\n",
    "                     (bandpass, drop_himo, [('out_file','in_file')]),\n",
    "                     \n",
    "                     (drop_himo,datasink,[('out_file','fully_processed_func')]),\n",
    "                     (denoise_func,datasink,[('weights','denoising_weights'),\n",
    "                                             ('residuals','orig_denoised_func')])\n",
    "                     (reg2mni, datasink, [('out_file','reoriented_anat')]),\n",
    "                     (reg2mni2, datasink, [('out_file','mnireg_func')])\n",
    "                    ])\n",
    "preprocflow.base_dir = workflow_dir\n",
    "preprocflow.write_graph(graph2use='flat')\n",
    "preprocflow.run('MultiProc', plugin_args={'n_procs': 8, 'memory_gb':32})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
