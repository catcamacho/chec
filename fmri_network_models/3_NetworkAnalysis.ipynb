{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis\n",
    "\n",
    "This notebook performs network analysis across the entire episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "from pandas import DataFrame, read_csv\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode, JoinNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.interfaces.fsl import GLM, Split, Merge, Cluster\n",
    "from nipype.interfaces.fsl.maths import MathsCommand\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# Set study variables\n",
    "analysis_home = '/data/perlman/moochie/user_data/CamachoCat/ChEC/fmri_proc'\n",
    "templates_dir = '/data/perlman/moochie/user_data/CamachoCat/Aggregate_anats/templates'\n",
    "preproc_dir = analysis_home + '/proc/preproc'\n",
    "output_dir = analysis_home + '/proc/network_analysis'\n",
    "workflow_dir = analysis_home + '/workflows'\n",
    "affect_ratings = analysis_home + '/misc/ratings_20200427.csv'\n",
    "\n",
    "gm_mask = templates_dir + '/lcbd_template_2mm_gm.nii.gz'\n",
    "\n",
    "subject_info = read_csv(analysis_home + '/misc/subjectinfo.csv', index_col=None)\n",
    "subject_info = subject_info[subject_info['usable.25']==1]\n",
    "subjects_list = subject_info['SubjID'].tolist()\n",
    "\n",
    "# data collection specs\n",
    "TR = 0.8 #in seconds\n",
    "duration= 1284 # in seconds\n",
    "wind_dur=45 #in seconds\n",
    "wind_offset=15 #in seconds\n",
    "nan_val = 99999\n",
    "\n",
    "template_atlas = analysis_home + '/template/MMP_subcort_warped.nii.gz'\n",
    "template_atlas_key = analysis_home + '/template/MMP_subcort.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subjects list\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subject_id', subjects_list)]\n",
    "\n",
    "# Pull files\n",
    "file_template = {'trim_func': preproc_dir + '/fully_processedtrim/{subject_id}/lomo_trim_func.nii.gz',\n",
    "                 'nan_func': preproc_dir + '/fully_processednan/{subject_id}/lomo_nan_func.nii.gz'}\n",
    "selectfiles = Node(SelectFiles(file_template), name='selectfiles')\n",
    "\n",
    "# Sink data of interest \n",
    "substitutions = [('_subject_id_', ''),\n",
    "                 ('_wind_dur_',''),\n",
    "                 ('wind_offset_',''),\n",
    "                 ('_covariates_..data..perlman..moochie..user_data..CamachoCat..ChEC..fmri_proc..misc..group_covariates_','')] #output file name substitutions\n",
    "datasink = Node(DataSink(base_directory = output_dir,\n",
    "                        container = output_dir,\n",
    "                        substitutions = substitutions), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make functional parcellation based on sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data\n",
    "\n",
    "# create mean timeseries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create overall connectivity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(func,atlas,atlas_labels):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import abspath\n",
    "    from nilearn.input_data import NiftiLabelsMasker\n",
    "    from nilearn.connectome import ConnectivityMeasure\n",
    "    from nilearn import plotting\n",
    "    import numpy as np\n",
    "    from pandas import read_csv, DataFrame\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    labels_df = read_csv(atlas_labels, index_col=None)\n",
    "    labels = labels_df['region_name'].to_list()\n",
    "    masker = NiftiLabelsMasker(labels_img=atlas, standardize=True)\n",
    "    time_series = masker.fit_transform(func)\n",
    "\n",
    "    correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "    correlation_matrix = correlation_measure.fit_transform([time_series])[0]\n",
    "    correlation_matrix[correlation_matrix==1]=0\n",
    "    conn_z = 0.5*np.log((1+correlation_matrix)/(1-correlation_matrix))\n",
    "    corr_mat_df = DataFrame(correlation_matrix,columns=labels,index=labels)\n",
    "    corr_mat_df.to_csv('correlation_matrix.csv')\n",
    "\n",
    "    plt.figure()\n",
    "    plotting.plot_matrix(correlation_matrix, figure=(10, 8), labels=labels,\n",
    "                         vmax=0.8, vmin=-0.8, reorder=True)\n",
    "    plt.savefig('corr_matrix.svg')\n",
    "    plt.close()\n",
    "    \n",
    "    corr_mat_fig = abspath('corr_matrix.svg')\n",
    "    corr_matrix = abspath('correlation_matrix.csv')\n",
    "    \n",
    "    return(corr_matrix, corr_mat_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File handling Nodes\n",
    "calc_connectivity = Node(Function(input_names=['func','atlas','atlas_labels'], \n",
    "                                  output_names=['corr_matrix','corr_mat_fig'], \n",
    "                                  function=correlation_matrix), \n",
    "                         name='calc_connectivity')\n",
    "calc_connectivity.inputs.atlas = template_atlas\n",
    "calc_connectivity.inputs.atlas_labels = template_atlas_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "connect_flow = Workflow(name='connect_flow')\n",
    "connect_flow.connect([(infosource,selectfiles, [('subject_id','subject_id')]),\n",
    "                      (selectfiles, calc_connectivity, [('trim_func','func')]),\n",
    "                      \n",
    "                      (calc_connectivity, datasink, [('corr_matrix','correlation_matrix'),\n",
    "                                                     ('corr_mat_fig','corr_matrix_plot')])\n",
    "                     ])\n",
    "\n",
    "connect_flow.base_dir = workflow_dir\n",
    "#connect_flow.write_graph(graph2use='flat')\n",
    "connect_flow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from pandas import read_csv, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "labels_df = read_csv(template_atlas_key, index_col=None)\n",
    "\n",
    "group_conn_data = read_csv(output_dir + '/correlation_matrix/{0}/correlation_matrix.csv'.format(subjects_list[0]), index_col=0)\n",
    "group_conn_mat = group_conn_data.to_numpy()\n",
    "group_conn_mat = np.expand_dims(group_conn_mat, axis=2)\n",
    "\n",
    "for sub in subjects_list[1:]:\n",
    "    temp = read_csv(output_dir + '/correlation_matrix/{0}/correlation_matrix.csv'.format(sub), index_col=0)\n",
    "    temp_mat = np.expand_dims(temp.to_numpy(),axis=2)\n",
    "    group_conn_mat = np.concatenate((group_conn_mat,temp_mat),axis=2)\n",
    "    \n",
    "mean_conn_data = np.average(group_conn_mat,axis=2)\n",
    "mean_conn_df = DataFrame(mean_conn_data, columns=labels_df['region_name'].tolist(), index=labels_df['region_name'].tolist())\n",
    "labels_df = labels_df.sort_values(by=['network_num'])\n",
    "mean_conn_df = mean_conn_df.reindex(labels_df['region_name'].tolist(), columns=labels_df['region_name'].to_list())\n",
    "mean_conn_df.to_csv('group_mean_z.csv')\n",
    "\n",
    "plt.figure()\n",
    "plotting.plot_matrix(mean_conn_df.to_numpy(), figure=(6, 6), labels=mean_conn_df.columns.to_list(), reorder=True,\n",
    "                     vmax=0.8, vmin=-0.8)\n",
    "plt.savefig(output_dir+'/group_mean_corr_z_matrix.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bct\n",
    "import pandas as pd\n",
    "\n",
    "labels_df = read_csv(template_atlas_key, index_col=None)\n",
    "labels_df = labels_df.sort_values(by=['network_num'])\n",
    "col_labels = ['N{0}_cc'.format(x) for x in range(0,8)] + ['N{0}_corr'.format(x) for x in range(0,8)]\n",
    "coeff_data = pd.DataFrame(columns=col_labels)\n",
    "final_comms = labels_df.loc[:,['network_num','region_name']]\n",
    "\n",
    "for sub in subjects_list:\n",
    "    idx = pd.IndexSlice\n",
    "    temp = read_csv(output_dir + '/correlation_matrix/{0}/correlation_matrix.csv'.format(sub), index_col=0)\n",
    "    temp = temp.reindex(labels_df['region_name'].tolist(),columns=labels_df['region_name'].tolist())\n",
    "    temp.columns = pd.MultiIndex.from_frame(final_comms, names=['network','region'])\n",
    "    temp.index = pd.MultiIndex.from_frame(final_comms, names=['network','region'])\n",
    "    for n in range(0,8):\n",
    "        net = temp.loc[idx[n,n]]\n",
    "        coeff_data.loc[sub,'N{0}_cc'.format(n)] = bct.clustering_coef_wu(net).mean()\n",
    "        net[net==1]=np.nan\n",
    "        coeff_data.loc[sub,'N{0}_corr'.format(n)] = np.nanmean(net.to_numpy())\n",
    "coeff_data.to_csv('ahkj_conn_cc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "covariates='/data/perlman/moochie/user_data/CamachoCat/ChEC/fmri_proc/misc/group_covariates_full.csv'\n",
    "model_data = pd.read_csv(covariates,index_col=0)\n",
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "subject_beta_mats=glob(output_dir +'/correlation_matrix/*/correlation_matrix.csv')\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "labels_df = read_csv(template_atlas_key, index_col=None)\n",
    "labels_df = labels_df.sort_values(by=['network_num'])\n",
    "final_comms = labels_df.loc[:,['network_num','region_name']]\n",
    "\n",
    "subject_beta_mats = sorted(subject_beta_mats)\n",
    "\n",
    "sub_mats = []\n",
    "for sub in subject_beta_mats:\n",
    "    t = pd.read_csv(sub, index_col=0)\n",
    "    t = t.reindex(labels_df['region_name'].tolist(),columns=labels_df['region_name'].tolist())\n",
    "    t.columns = pd.MultiIndex.from_frame(final_comms, names=['network','region'])\n",
    "    t.index = pd.MultiIndex.from_frame(final_comms, names=['network','region'])\n",
    "    t[t==1]= np.nan\n",
    "    t = t.groupby(level=0).mean()\n",
    "    t = t.groupby(level=0, axis=1).mean()\n",
    "    t = t.drop(labels=[0], axis=0)\n",
    "    t = t.drop(labels=[0], axis=1)\n",
    "    t = t.to_numpy()\n",
    "    t = np.expand_dims(t,axis=2)\n",
    "    sub_mats.append(t)\n",
    "sub_data = np.concatenate(sub_mats,axis=2)\n",
    "\n",
    "X = model_data[['intercept','age_cent','male','censoredFD']].to_numpy()\n",
    "\n",
    "tstats = np.zeros((sub_data.shape[0],sub_data.shape[0],4))\n",
    "pvals = np.zeros((sub_data.shape[0],sub_data.shape[0],4))\n",
    "\n",
    "for a in range(0,sub_data.shape[0]):\n",
    "    for b in range(0,sub_data.shape[0]):\n",
    "        Y=sub_data[a,b,:]\n",
    "        model = sm.OLS(Y,X)\n",
    "        res = model.fit()\n",
    "        tstats[a,b,:] = res.tvalues\n",
    "        pvals[a,b,:] = res.pvalues\n",
    "        \n",
    "np.save(output_dir + '/full_conn_net_plots/tstats_networks.npy',tstats)\n",
    "np.save(output_dir + '/full_conn_net_plots/pvals_networks.npy',pvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from chord import Chord\n",
    "import matplotlib.pyplot as plt\n",
    "tstats = np.load(output_dir + '/full_conn_net_plots/tstats_networks.npy')\n",
    "labels_df = read_csv(template_atlas_key, index_col=None)\n",
    "labels = ['visual','somatomotor','dors_att','vent_att','limbic','frontopar','default']\n",
    "print(labels)\n",
    "tstats[pvals>(0.005)]=0\n",
    "\n",
    "for num in range(0,4):\n",
    "    mat=tstats[:,:,num]\n",
    "\n",
    "    plotting.plot_matrix(mat, figure=(6, 6), labels=labels, reorder=True,\n",
    "                         vmax=5, vmin=-5)\n",
    "    plt.savefig(output_dir + '/full_conn_net_plots/conn_{0}.svg'.format(num))\n",
    "    \n",
    "mean_conn = np.mean(sub_data, axis=2)\n",
    "plotting.plot_matrix(mean_conn, figure=(6, 6), labels=labels, reorder=True,\n",
    "                     vmax=0.5, vmin=-0.5)\n",
    "plt.savefig(output_dir + '/full_conn_net_plots/mean_conn.svg'.format(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dynamic connectivity timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_connect(func,rate,wind_dur,wind_offset,TR,atlas,nan_val):\n",
    "    '''This function takes a BOLD timeseries and a ratings series of the same length and \n",
    "    uses a sliding window approach to create a new connectivity timeseries.  Windows with\n",
    "    too many NaNs (1/2 window duration or more) are dropped from the connectivity timeseries and \n",
    "    the ratings timeseries.\n",
    "    \n",
    "    Inputs:\n",
    "        func:  the subject's nifti timeseries data.\n",
    "        rate:  the ratings timeseries (sampled at 1 per TR)\n",
    "        wind_dur:  width or duration fo sliding window in seconds\n",
    "        wind_offset:  the gap (in seconds) between the start times of adjacent windows\n",
    "        TR:  repetition time of the fMRI sequence\n",
    "        atlas:  parcellation scheme to use for unmasking the fMRI data\n",
    "        nan_val:  the value used to encode NaN'ed volumes (e.g., due to high motion)\n",
    "        \n",
    "    Outputs:\n",
    "        connect_ts:  dynamic connectivity timeseries\n",
    "        rate_ts:  newly sampled ratings timeseries\n",
    "    '''\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import abspath\n",
    "    from nilearn.input_data import NiftiLabelsMasker\n",
    "    from nilearn.connectome import ConnectivityMeasure\n",
    "    import numpy as np\n",
    "    from pandas import read_csv, DataFrame\n",
    "    \n",
    "    masker = NiftiLabelsMasker(labels_img=atlas, standardize=True)\n",
    "    func_ts = masker.fit_transform(func)\n",
    "    func_ts[func_ts==nan_val]=np.nan\n",
    "    rate_ts = read_csv(rate, index_col=0)\n",
    "    ratings = rate_ts.to_numpy()\n",
    "\n",
    "    duration = len(func_ts)\n",
    "    wind_dur_tr = int(wind_dur/TR)\n",
    "    wind_overlap = int(wind_offset/TR)\n",
    "    min_wind_dur = int(wind_dur*0.67)\n",
    "\n",
    "    start = 0\n",
    "    dyn_conn_mats = []\n",
    "    dyn_conn_rate = DataFrame(columns=rate_ts.columns)\n",
    "    corr_meas = ConnectivityMeasure(kind='correlation')\n",
    "    \n",
    "    while start+wind_dur_tr < duration:\n",
    "        end = start + wind_dur_tr\n",
    "        temp_ts = func_ts[start:end,:]\n",
    "        temp_rate = ratings[start:end,:]\n",
    "        tmask = np.isfinite(temp_ts[:,0])\n",
    "        temp_rate = temp_rate[tmask]\n",
    "        temp_ts = temp_ts[tmask]\n",
    "        if temp_ts.shape[0]>=min_wind_dur:\n",
    "            corr_mat = corr_meas.fit_transform([temp_ts])[0]\n",
    "            t = np.expand_dims(corr_mat, axis=2)\n",
    "            dyn_conn_mats.append(t)\n",
    "            temp_rate = np.mean(temp_rate,axis=0)\n",
    "            dyn_conn_rate.loc[start,:] = temp_rate\n",
    "        start += wind_offset\n",
    "\n",
    "    dyn_conn = np.concatenate(dyn_conn_mats, axis=2)\n",
    "    np.savez_compressed('dyn_conn_{0}.npz'.format(wind_dur),dyn_conn=dyn_conn)\n",
    "    dyn_conn_rate.to_csv('dyn_rate_{0}.csv'.format(wind_dur))\n",
    "    connect_ts = abspath('dyn_conn_{0}.npz'.format(wind_dur))\n",
    "    rate_ts = abspath('dyn_rate_{0}.csv'.format(wind_dur))\n",
    "    return(connect_ts, rate_ts)\n",
    "    \n",
    "def sliding_network_connect(func,rate,wind_dur,wind_offset,TR,atlas,net_labels,nan_val):\n",
    "    '''This function takes a BOLD timeseries and a ratings series of the same length and \n",
    "    uses a sliding window approach to create a new connectivity timeseries.  Windows with\n",
    "    too many NaNs (1/2 window duration or more) are dropped from the connectivity timeseries and \n",
    "    the ratings timeseries.\n",
    "    \n",
    "    Inputs:\n",
    "        func:  the subject's nifti timeseries data.\n",
    "        rate:  the ratings timeseries (sampled at 1 per TR)\n",
    "        wind_dur:  width or duration fo sliding window in seconds\n",
    "        wind_offset:  the gap (in seconds) between the start times of adjacent windows\n",
    "        TR:  repetition time of the fMRI sequence\n",
    "        atlas:  parcellation scheme to use for unmasking the fMRI data\n",
    "        net_labels: a file containing a dataframe with region and network labels\n",
    "        nan_val:  the value used to encode NaN'ed volumes (e.g., due to high motion)\n",
    "        \n",
    "    Outputs:\n",
    "        connect_ts:  dynamic connectivity timeseries\n",
    "        rate_ts:  newly sampled ratings timeseries\n",
    "    '''\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import abspath\n",
    "    from nilearn.input_data import NiftiLabelsMasker\n",
    "    from nilearn.connectome import ConnectivityMeasure\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    labels_df = pd.read_csv(net_labels, index_col=None)\n",
    "    orig_labels = labels_df['region_name'].to_list()\n",
    "    labels_df = labels_df.sort_values(by=['network_num'])\n",
    "    final_comms = labels_df.loc[:,['network_num','region_name']]\n",
    "\n",
    "    masker = NiftiLabelsMasker(labels_img=atlas, standardize=False)\n",
    "    func_ts = masker.fit_transform(func)\n",
    "    func_ts[func_ts>=nan_val]=np.nan\n",
    "    rate_ts = pd.read_csv(rate, index_col=0)\n",
    "    ratings = rate_ts.to_numpy()\n",
    "    mask = np.isfinite(func_ts)\n",
    "    mask = np.mean(mask,axis=1)\n",
    "    mask = mask==1\n",
    "\n",
    "    duration = len(func_ts)\n",
    "    wind_dur_tr = int(wind_dur/TR)\n",
    "    wind_overlap = int(wind_offset/TR)\n",
    "    min_wind_dur = int(wind_dur*0.67)\n",
    "\n",
    "    start = 0\n",
    "    dyn_conn_mats = []\n",
    "    dyn_conn_rate = pd.DataFrame(columns=rate_ts.columns)\n",
    "    corr_meas = ConnectivityMeasure(kind='correlation')\n",
    "    \n",
    "    while start+wind_dur_tr < duration:\n",
    "        end = start + wind_dur_tr\n",
    "        temp_ts = func_ts[start:end,:]\n",
    "        temp_rate = ratings[start:end,:]\n",
    "        tmask = np.isfinite(temp_ts[:,0])\n",
    "        temp_rate = temp_rate[tmask]\n",
    "        temp_ts = temp_ts[tmask]\n",
    "        if temp_ts.shape[0]>=min_wind_dur:\n",
    "            corr_mat = corr_meas.fit_transform([temp_ts])[0]\n",
    "            t = pd.DataFrame(corr_mat, index=orig_labels, columns=orig_labels)\n",
    "            t = t.reindex(labels_df['region_name'].tolist(),columns=labels_df['region_name'].tolist())\n",
    "            t.columns = pd.MultiIndex.from_frame(final_comms, names=['network','region'])\n",
    "            t.index = pd.MultiIndex.from_frame(final_comms, names=['network','region'])\n",
    "            t[t==1]= np.nan\n",
    "            t = t.groupby(level=0).mean()\n",
    "            t = t.groupby(level=0, axis=1).mean()\n",
    "            t = t.drop(labels=[0], axis=0)\n",
    "            t = t.drop(labels=[0], axis=1)\n",
    "            t = np.expand_dims(t, axis=2)\n",
    "            dyn_conn_mats.append(t)\n",
    "            temp_rate = np.mean(temp_rate,axis=0)\n",
    "            dyn_conn_rate.loc[start,:] = temp_rate\n",
    "        start += wind_offset\n",
    "\n",
    "    dyn_conn = np.concatenate(dyn_conn_mats, axis=2)\n",
    "    np.savez_compressed('dyn_conn_{0}.npz'.format(wind_dur),dyn_conn=dyn_conn)\n",
    "    dyn_conn_rate.to_csv('dyn_rate_{0}.csv'.format(wind_dur))\n",
    "    connect_ts = abspath('dyn_conn_{0}.npz'.format(wind_dur))\n",
    "    rate_ts = abspath('dyn_rate_{0}.csv'.format(wind_dur))\n",
    "    return(connect_ts, rate_ts)\n",
    "\n",
    "def adjmat_glm(matrix_ts,predictors):\n",
    "    '''This function takes a matrix timeseries and regresses a set of predictors from \n",
    "    each off-diagonal matrix value. \n",
    "    \n",
    "    Inputs:\n",
    "        matrix_ts: compressed numpy file with matrix timeseries\n",
    "        predictors: pandas dataframe with the predictors\n",
    "    \n",
    "    Outputs: \n",
    "        beta_files: list of files named for the columns in the predictors dataframe, each \n",
    "        file containing a matrix with OLS coefficients (betas).'''\n",
    "    \n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    import numpy as np\n",
    "    from pandas import read_csv\n",
    "    import statsmodels.api as sm\n",
    "    from os.path import abspath\n",
    "    \n",
    "    mat_ts = np.load(matrix_ts)\n",
    "    mat_ts = mat_ts['dyn_conn']\n",
    "    pred = read_csv(predictors, index_col=0)\n",
    "\n",
    "    beta_files = []\n",
    "\n",
    "    for var in pred.columns:\n",
    "        X = sm.add_constant(pred[var].to_numpy())\n",
    "        betas = np.zeros((mat_ts.shape[0],mat_ts.shape[1]))\n",
    "        for a in range(0,mat_ts.shape[0]):\n",
    "            for b in range(0,mat_ts.shape[0]):\n",
    "                if a!=b:\n",
    "                    Y=mat_ts[a,b,:]\n",
    "                    model = sm.OLS(Y,X)\n",
    "                    res=model.fit()\n",
    "                    betas[a,b]=res.params[1]\n",
    "                else:\n",
    "                    pass\n",
    "        np.save('betas_{0}.npy'.format(var),betas)        \n",
    "        beta_files.append(abspath('betas_{0}.npy'.format(var)))\n",
    "    \n",
    "    return(beta_files)\n",
    "\n",
    "def adjmat_net_glm(matrix_ts,predictors):\n",
    "    '''This function takes a matrix timeseries and regresses a set of predictors from \n",
    "    each off-diagonal matrix value. \n",
    "    \n",
    "    Inputs:\n",
    "        matrix_ts: compressed numpy file with matrix timeseries\n",
    "        predictors: pandas dataframe with the predictors\n",
    "    \n",
    "    Outputs: \n",
    "        beta_files: list of files named for the columns in the predictors dataframe, each \n",
    "        file containing a matrix with OLS coefficients (betas).'''\n",
    "    \n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    import numpy as np\n",
    "    from pandas import read_csv\n",
    "    import statsmodels.api as sm\n",
    "    from os.path import abspath\n",
    "    \n",
    "    mat_ts = np.load(matrix_ts)\n",
    "    mat_ts = mat_ts['dyn_conn']\n",
    "    pred = read_csv(predictors, index_col=0)\n",
    "\n",
    "    beta_files = []\n",
    "\n",
    "    for var in pred.columns:\n",
    "        X = sm.add_constant(pred[var].to_numpy())\n",
    "        betas = np.zeros((mat_ts.shape[0],mat_ts.shape[1]))\n",
    "        for a in range(0,mat_ts.shape[0]):\n",
    "            for b in range(0,mat_ts.shape[0]):\n",
    "                Y=mat_ts[a,b,:]\n",
    "                model = sm.OLS(Y,X)\n",
    "                res=model.fit()\n",
    "                betas[a,b]=res.params[1]\n",
    "\n",
    "        np.save('betas_{0}.npy'.format(var),betas)        \n",
    "        beta_files.append(abspath('betas_{0}.npy'.format(var)))\n",
    "    \n",
    "    return(beta_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window = Node(Function(input_names=['func','rate','wind_dur','wind_offset',\n",
    "                                            'TR','atlas','nan_val'], \n",
    "                               output_names=['connect_ts', 'rate_ts'],\n",
    "                               function=sliding_connect),\n",
    "                      name='sliding_window')\n",
    "sliding_window.inputs.TR=TR\n",
    "sliding_window.inputs.nan_val=nan_val\n",
    "sliding_window.inputs.atlas=template_atlas\n",
    "#sliding_window.inputs.wind_offset=wind_offset\n",
    "sliding_window.inputs.rate=affect_ratings\n",
    "sliding_window.iterables = [('wind_dur',[45,60,75]),('wind_offset',[15,20,25])]\n",
    "sliding_window.synchronize = True\n",
    "\n",
    "sliding_net = Node(Function(input_names=['func','rate','wind_dur','wind_offset',\n",
    "                                         'TR','atlas','net_labels','nan_val'], \n",
    "                            output_names=['connect_ts', 'rate_ts'],\n",
    "                            function=sliding_network_connect),\n",
    "                   name='sliding_net')\n",
    "sliding_net.inputs.TR=TR\n",
    "sliding_net.inputs.nan_val=90000\n",
    "sliding_net.inputs.atlas=template_atlas\n",
    "#sliding_net.inputs.wind_offset=wind_offset\n",
    "#sliding_net.inputs.wind_dur=wind_dur\n",
    "sliding_net.inputs.rate=affect_ratings\n",
    "sliding_net.inputs.net_labels=template_atlas_key\n",
    "sliding_net.iterables = [('wind_dur',[45,60,75]),('wind_offset',[15,20,25])]\n",
    "sliding_net.synchronize = True\n",
    "\n",
    "mat_glm = Node(Function(input_names=['matrix_ts','predictors'],\n",
    "                        output_names=['beta_files'],\n",
    "                        function=adjmat_glm), \n",
    "               name='mat_glm')\n",
    "\n",
    "mat_net_glm = Node(Function(input_names=['matrix_ts','predictors'],\n",
    "                            output_names=['beta_files'],\n",
    "                            function=adjmat_net_glm), \n",
    "               name='mat_net_glm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dynconn_flow = Workflow(name='dynconn_flow')\n",
    "dynconn_flow.connect([(infosource,selectfiles, [('subject_id','subject_id')]),\n",
    "                      #(selectfiles, sliding_window, [('nan_func','func')]),\n",
    "                      #(sliding_window, mat_glm, [('connect_ts','matrix_ts'),\n",
    "                      #                           ('rate_ts','predictors')]),\n",
    "                      (selectfiles, sliding_net, [('nan_func','func')]),\n",
    "                      (sliding_net, mat_net_glm, [('connect_ts','matrix_ts'),\n",
    "                                                  ('rate_ts','predictors')]),\n",
    "                      \n",
    "                      (sliding_net, datasink, [('connect_ts','dyn_net_ts'),\n",
    "                                               ('rate_ts','dyn_rate_ts')]),\n",
    "                      #(mat_glm, datasink, [('beta_files','dyn_conn_betas')]),\n",
    "                      (mat_net_glm, datasink, [('beta_files','dyn_net_conn_betas')])\n",
    "                     ])\n",
    "\n",
    "dynconn_flow.base_dir = workflow_dir\n",
    "#dynconn_flow.write_graph(graph2use='flat')\n",
    "dynconn_flow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':30})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group level pipeline for dynamic connectivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_group_analysis(subject_beta_mats,covariates):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    from scipy import stats\n",
    "    import pandas as pd\n",
    "    from os.path import abspath\n",
    "    \n",
    "    subject_beta_mats = sorted(subject_beta_mats)\n",
    "\n",
    "    sub_mats = []\n",
    "    for sub in subject_beta_mats:\n",
    "        t = np.load(sub)\n",
    "        t = np.expand_dims(t,axis=2)\n",
    "        sub_mats.append(t)\n",
    "    sub_data = np.concatenate(sub_mats,axis=2)\n",
    "\n",
    "    model_data = pd.read_csv(covariates,index_col=0)\n",
    "    X = model_data.to_numpy()\n",
    "\n",
    "    tstats = np.zeros((sub_data.shape[0],sub_data.shape[0],len(model_data.columns)))\n",
    "    pvals = np.zeros((sub_data.shape[0],sub_data.shape[0],len(model_data.columns)))\n",
    "\n",
    "    for a in range(0,sub_data.shape[0]):\n",
    "        for b in range(0,sub_data.shape[0]):\n",
    "            Y=sub_data[a,b,:]\n",
    "            model = sm.OLS(Y,X)\n",
    "            res = model.fit()\n",
    "            tstats[a,b,:] = res.tvalues\n",
    "            pvals[a,b,:] = res.pvalues\n",
    "\n",
    "    np.save('tstats.npy',tstats)\n",
    "    np.save('pvals.npy',pvals)\n",
    "    t_mat=abspath('tstats.npy')\n",
    "    p_mat=abspath('pvals.npy')\n",
    "\n",
    "    return(t_mat,p_mat)\n",
    "\n",
    "def plot_mat_results(t_mat, p_mat, alpha, labels):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    import numpy as np\n",
    "    from nilearn import plotting\n",
    "    from os.path import abspath\n",
    "    import matplotlib.pyplot as plt\n",
    "    tstats = np.load(t_mat)\n",
    "    pvals = np.load(p_mat)\n",
    "    tstats[pvals>alpha]=0\n",
    "    \n",
    "    print(tstats.shape)\n",
    "    print(len(labels))\n",
    "    \n",
    "    plots = []\n",
    "    for term in range(0,tstats.shape[2]):\n",
    "        mat=tstats[:,:,term]\n",
    "        plotting.plot_matrix(mat, figure=(6, 6), labels=labels, reorder=False,\n",
    "                             vmax=5, vmin=-5)\n",
    "        plt.savefig('conn_{0}.svg'.format(term))\n",
    "        plots.append(abspath('conn_{0}.svg'.format(term)))\n",
    "    \n",
    "    return(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_template={'betas':output_dir+'/dyn_net_conn_betas/{subject_id}/{wind}/betas_{cond}.npy'}\n",
    "selectbetas = Node(SelectFiles(beta_template),name='selectbetas')\n",
    "selectbetas.iterables=[('cond',['negative','positive']),('wind',['45_15','60_20','75_25'])]\n",
    "\n",
    "group_analysis = JoinNode(Function(input_names=['subject_beta_mats','covariates'],\n",
    "                                   output_names=['t_mat','p_mat'],\n",
    "                                   function=mat_group_analysis),\n",
    "                          name='group_analysis', \n",
    "                          joinfield=['subject_beta_mats'], \n",
    "                          joinsource=infosource)\n",
    "group_analysis.iterables = ('covariates',[analysis_home + '/misc/group_covariates_ec.csv',\n",
    "                                          analysis_home + '/misc/group_covariates_neg.csv',\n",
    "                                          analysis_home + '/misc/group_covariates_sur.csv',\n",
    "                                          analysis_home + '/misc/group_covariates_age.csv'])\n",
    "\n",
    "plot_mat_glm = Node(Function(input_names=['t_mat','p_mat','alpha','labels'],\n",
    "                             output_names=['plots'],\n",
    "                             function=plot_mat_results), \n",
    "                    name='plot_mat_glm')\n",
    "plot_mat_glm.inputs.labels = ['visual','somatomotor','dors_att',\n",
    "                              'vent_att','limbic','frontopar','default']\n",
    "plot_mat_glm.inputs.alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dynconn_group_flow = Workflow(name='dynconn_group_flow')\n",
    "dynconn_group_flow.connect([(infosource,selectbetas, [('subject_id','subject_id')]),\n",
    "                            (selectbetas, group_analysis, [('betas','subject_beta_mats')]),\n",
    "                            (group_analysis, plot_mat_glm, [('t_mat','t_mat'),\n",
    "                                                            ('p_mat','p_mat')]),\n",
    "                            \n",
    "                            (group_analysis, datasink, [('t_mat','dyn_conn_t_mat'),\n",
    "                                                        ('p_mat','dyn_conn_p_mat')]), \n",
    "                            (plot_mat_glm, datasink, [('plots','dyn_conn_t_plots')])\n",
    "                           ])\n",
    "\n",
    "dynconn_group_flow.base_dir = workflow_dir\n",
    "#dynconn_group_flow.write_graph(graph2use='flat')\n",
    "dynconn_group_flow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
