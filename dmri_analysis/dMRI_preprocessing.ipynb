{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dMRI Preprocessing\n",
    "\n",
    "This note book processes multiband diffusion weighted imaging for tensor-based analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.pipeline.engine import Workflow, Node, JoinNode, MapNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.interfaces.fsl import BET, MeanImage, ApplyTOPUP, TOPUP, Merge,ExtractROI\n",
    "from nipype.interfaces.ants import RegistrationSynQuick, ApplyTransforms\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# Study-specific variables\n",
    "project_home = '/data/perlman/moochie/user_data/CamachoCat/ChEC/dmri_proc'\n",
    "output_dir = project_home + '/proc/preprocessing'\n",
    "workflow_dir = project_home + '/workflows'\n",
    "raw_dir = '/data/perlman/moochie/study_data/ChEC/MRI_data'\n",
    "phase_encoding_file = project_home + '/misc/chec_encoding_file.txt'\n",
    "\n",
    "template_2mm = '/data/perlman/moochie/user_data/CamachoCat/Aggregate_anats/templates/lcbd_template_2mm_brain.nii.gz'\n",
    "subjects_list = open(project_home + '/misc/chec_subjects.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Universal nodes\n",
    "\n",
    "# get subjects list\n",
    "infosource = Node(IdentityInterface(fields=['subjid']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "# Sink data of interest\n",
    "substitutions = [('_subjid_', '')] #output file name substitutions\n",
    "datasink = Node(DataSink(base_directory = output_dir,\n",
    "                        container = output_dir,\n",
    "                        substitutions = substitutions), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unwarping workflow\n",
    "\n",
    "This workflow includes both unwarping and eddy correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select dMRI data\n",
    "dmri_template = {'dmri_pe0': raw_dir + '/sub-{subjid}/dwi/sub-{subjid}_98dir_AP.nii.gz',\n",
    "                 'bval':raw_dir + '/sub-{subjid}/dwi/sub-{subjid}_98dir_AP.bval',\n",
    "                 'bvec':raw_dir + '/sub-{subjid}/dwi/sub-{subjid}_98dir_AP.bvec'}\n",
    "selectdmri = Node(SelectFiles(dmri_template), name='selectdmri')\n",
    "\n",
    "pes_template={'pes':raw_dir + '/sub-{subjid}/dwi/sub-{subjid}_98dir_{pe}.nii.gz'}\n",
    "selectpes = Node(SelectFiles(pes_template),name='selectpes')\n",
    "selectpes.iterables=('pe',['AP','PA'])\n",
    "\n",
    "# include only the first volume of each PE volume\n",
    "trim_pes = Node(ExtractROI(t_min=0,t_size=1,roi_file='pe_trimmed.nii.gz'),name='trim_pes')\n",
    "\n",
    "# merge to 1 file for topup to calculate the fieldcoef\n",
    "merge_pes = JoinNode(Merge(dimension='t',\n",
    "                           merged_file='merged_pes.nii.gz'),\n",
    "                     name='merge_pes', joinsource='selectpes', joinfield='in_files')\n",
    "\n",
    "# actually do the unwarping\n",
    "topup = Node(TOPUP(encoding_file=phase_encoding_file), name='topup')\n",
    "\n",
    "apply_topup = Node(ApplyTOPUP(in_index=[1], encoding_file=phase_encoding_file,\n",
    "                              method='jac', out_corrected='dmri_unwarped.nii.gz'),\n",
    "                   name='apply_topup')\n",
    "\n",
    "# average dMRI so we can make a mask\n",
    "avg_dmri = Node(MeanImage(), name='avg_dmri')\n",
    "\n",
    "# create a dMRI space brain mask using BET\n",
    "make_mask = Node(BET(mask=True), name='make_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prepreprocflow = Workflow(name='prepreprocflow')\n",
    "prepreprocflow.connect([(infosource,selectdmri, [('subjid','subjid')]),\n",
    "                        (infosource, selectpes, [('subjid','subjid')]),\n",
    "                        (selectpes, trim_pes, [('pes','in_file')]),\n",
    "                        (trim_pes, merge_pes,[('roi_file','in_files')]),\n",
    "                        (merge_pes, topup, [('merged_file','in_file')]),\n",
    "                        (topup, apply_topup, [('out_fieldcoef','in_topup_fieldcoef'), \n",
    "                                              ('out_movpar','in_topup_movpar')]),\n",
    "                        (selectdmri, apply_topup, [('dmri_pe0','in_files')]),\n",
    "                        (apply_topup, avg_dmri, [('out_corrected','in_file')]),\n",
    "                        (avg_dmri, make_mask, [('out_file','in_file')]),\n",
    "                        (make_mask, datasink, [('mask_file','in_mask')]),\n",
    "                        (apply_topup, datasink, [('out_corrected','unwarped_niftis')])\n",
    "                       ])\n",
    "\n",
    "prepreprocflow.base_dir = workflow_dir\n",
    "#prepreprocflow.write_graph(graph2use='flat')\n",
    "prepreprocflow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for subjects without both encoding directions\n",
    "This workflow makes group a average fieldmap as done in Laumann et al. 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make3DTemplate(subject_vols, num_proc, output_prefix):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from os.path import abspath, split\n",
    "    from os import getcwd\n",
    "    from shutil import copyfile\n",
    "    import subprocess \n",
    "\n",
    "    curr_dir = getcwd()\n",
    "\n",
    "    #copy data into current directory\n",
    "    for T in range(0,len(subject_vols)):\n",
    "        [dirname,filename] = split(subject_vols[T])\n",
    "        copyfile(subject_vols[T],curr_dir + '/' + str(T)+'_'+filename)\n",
    "\n",
    "    # -c flag is control for local computing (2= use localhost; required for -j flag)\n",
    "    # -j flag is for number of processors allowed\n",
    "\n",
    "    subprocess.check_call(['antsMultivariateTemplateConstruction2.sh','-d','3','-o', \n",
    "                           output_prefix,'-r','1','-c','2','-n','0','-j', str(num_proc), '*.nii.gz'], shell=True)\n",
    "    \n",
    "    sample_template = abspath(output_prefix + 'template0.nii.gz')\n",
    "    \n",
    "    return(sample_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort IDs with good and bad fieldmaps\n",
    "subs_corr_fmap = ['1000', '1001', '1008', '1011', '1016', '1017', '1027', '1031',\n",
    "                  '1034', '1036', '1040', '1045', '1047', '1048', '1052', '1053'] #used to make group mean fieldmap\n",
    "subs_to_unwarp = ['1006', '1007', '1012', '1015', '1023', '1025', '1026', '1032',\n",
    "                  '1046', '1055']\n",
    "# get subjects list\n",
    "infosource = Node(IdentityInterface(fields=['subjid']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subs_to_unwarp)]\n",
    "\n",
    "# select good pes\n",
    "pe_template={'pe': project_home + '/misc/%s_pe_template0.nii.gz'}\n",
    "grab_pe_data = Node(DataGrabber(field_template=pe_template, \n",
    "                                sort_filelist=True,\n",
    "                                base_directory=raw_dir, \n",
    "                                template=project_home + '/misc/%s_pe_template0.nii.gz', \n",
    "                                infields=['dir'], \n",
    "                                template_args={'pe':[['dir']]}), \n",
    "                    name='grab_pe_data')\n",
    "grab_pe_data.iterables=('dir',['AP','PA'])\n",
    "\n",
    "# grab just first B0 volume for registration\n",
    "trim_b0 = Node(ExtractROI(t_min=0, t_size=1), name='trim_b0')\n",
    "\n",
    "# merge to 1 file for topup to calculate the fieldcoef\n",
    "merge_pes = JoinNode(Merge(dimension='t',\n",
    "                           merged_file='merged_pes.nii.gz'),\n",
    "                     name='merge_pes', joinsource='grab_pe_data', joinfield='in_files')\n",
    "\n",
    "#register template to subject data\n",
    "register2subject = Node(RegistrationSynQuick(dimension=3,\n",
    "                                             transform_type='a'), name='register2subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupunwarp = Workflow(name='groupunwarp')\n",
    "groupunwarp.connect([(infosource,selectdmri, [('subjid','subjid')]),\n",
    "                     (grab_pe_data, register2subject,[('pe','moving_image')]),\n",
    "                     (selectdmri, trim_b0, [('dmri_pe0','in_file')]),\n",
    "                     (trim_b0, register2subject, [('roi_file','fixed_image')]),\n",
    "                     (register2subject, merge_pes, [('warped_image','in_files')]),\n",
    "                     (merge_pes, topup, [('merged_file','in_file')]),\n",
    "                     (topup, apply_topup, [('out_fieldcoef','in_topup_fieldcoef'), \n",
    "                                           ('out_movpar','in_topup_movpar')]),\n",
    "                     (selectdmri, apply_topup, [('dmri_pe0','in_files')]),\n",
    "                     (apply_topup, avg_dmri, [('out_corrected','in_file')]),\n",
    "                     (avg_dmri, make_mask, [('out_file','in_file')]),\n",
    "                     (make_mask, datasink, [('mask_file','in_mask')]),\n",
    "                     (apply_topup, datasink, [('out_corrected','unwarped_niftis')])\n",
    "                    ])\n",
    "\n",
    "groupunwarp.base_dir = workflow_dir\n",
    "#groupunwarp.write_graph(graph2use='flat')\n",
    "groupunwarp.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':10})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
