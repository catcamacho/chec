{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dMRI Preprocessing\n",
    "\n",
    "This note book processes multiband diffusion weighted imaging for tensor-based analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.pipeline.engine import Workflow, Node, JoinNode, MapNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, FreeSurferSource\n",
    "from nipype.interfaces.fsl import Reorient2Std, BET, MeanImage, MCFLIRT, FLIRT, ApplyTOPUP, TOPUP, Eddy, ExtractROI\n",
    "from nipype.interfaces.freesurfer import MRIConvert, Binarize, FSCommand\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# Study-specific variables\n",
    "project_home = '/moochie/Cat/EmoGrow/dMRI_proc'\n",
    "output_dir = project_home + '/proc/preprocessing'\n",
    "workflow_dir = project_home + '/workflows'\n",
    "raw_dir = '/moochie/R01-EmoGrow/MRI_Data'\n",
    "phase_encoding_file = project_home + '/misc/acq_params.txt'\n",
    "eddy_index_file = project_home + '/misc/eddy_index_params.txt'\n",
    "\n",
    "#subjects_list = ['1000','1001','1002','1003','1004','1005','1006',\n",
    "#                 '1007','1008','1009','1011','1012','1015','1016',\n",
    "#                 '1017','1019','1021','1023','1025','1026', '1027','3000']\n",
    "subjects_list = open(project_home + '/misc/emogrow_subjects.txt').read().splitlines()\n",
    "#subjects_list = ['018']\n",
    "\n",
    "# FreeSurfer set up - change SUBJECTS_DIR \n",
    "fs_dir = '/moochie/Cat/Aggregate_anats/subjects_dir'\n",
    "FSCommand.set_default_subjects_dir(fs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Universal nodes\n",
    "\n",
    "# get subjects list\n",
    "infosource = Node(IdentityInterface(fields=['subjid']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "# FreeSurferSource - Data grabber specific for FreeSurfer data\n",
    "fssource = Node(FreeSurferSource(subjects_dir=fs_dir),\n",
    "                run_without_submitting=True,\n",
    "                name='fssource')\n",
    "\n",
    "def FSid(subjid):\n",
    "    from nipype import logging, config\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    fs_id = 'E'+str(subjid)\n",
    "    return(fs_id)\n",
    "\n",
    "fsid = Node(Function(input_names=['subjid'],\n",
    "                     output_names=['fs_id'], \n",
    "                     function=FSid), \n",
    "            name='fsid')\n",
    "\n",
    "# Sink data of interest\n",
    "substitutions = [('_subjid_', '')] #output file name substitutions\n",
    "datasink = Node(DataSink(base_directory = output_dir,\n",
    "                        container = output_dir,\n",
    "                        substitutions = substitutions), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unwarping workflow\n",
    "\n",
    "This workflow includes both unwarping and eddy correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select func dicoms\n",
    "def cvt_dicom(seqname,studypath,subjid):\n",
    "    from nipype import logging, config\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from glob import glob\n",
    "    from nipype.interfaces.freesurfer import MRIConvert\n",
    "    from os.path import abspath\n",
    "    \n",
    "    subjid = str(subjid)\n",
    "    dicoms = glob('%s/%s/%s*/MR.*' % (studypath, subjid, seqname))\n",
    "    print('%s/%s/%s*/MR.*' % (studypath, subjid, seqname))\n",
    "    dicom_file=dicoms[0]\n",
    "    \n",
    "    cvt = MRIConvert()\n",
    "    cvt.inputs.out_type = 'niigz'\n",
    "    cvt.inputs.in_file = dicom_file\n",
    "    cvt.inputs.out_file = seqname[0:13] + '.nii.gz'\n",
    "    cvt.run()\n",
    "    \n",
    "    nii_file = abspath(seqname[0:13] + '.nii.gz')\n",
    "    \n",
    "    bvec = nii_file.replace('.nii.gz','.voxel_space.bvecs')\n",
    "    bval = nii_file.replace('.nii.gz','.bvals')\n",
    "    return(nii_file, bvec, bval)\n",
    "\n",
    "def sort_pes(pes):\n",
    "    from nipype import logging, config\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from nipype.interfaces.fsl import Merge, ExtractROI\n",
    "    from os.path import abspath\n",
    "    \n",
    "    eroi = ExtractROI()\n",
    "    eroi.inputs.t_min = 0\n",
    "    eroi.inputs.t_size = 1\n",
    "    \n",
    "    for i in [0,1]:\n",
    "        if 'dMRI_dir98_AP' in pes[i]:\n",
    "            pe0 = pes[i]\n",
    "            pe_AP = pes[i]\n",
    "        elif 'dMRI_dir98_PA' in pes[i]:\n",
    "            pe_PA = pes[i]\n",
    "    \n",
    "    eroi.inputs.in_file = pe_AP\n",
    "    eroi.inputs.roi_file = 'dMRI_AP.nii.gz' \n",
    "    eroi.run()\n",
    "    pe_AP_1 = abspath('dMRI_AP.nii.gz')\n",
    "    \n",
    "    eroi.inputs.in_file = pe_PA\n",
    "    eroi.inputs.roi_file = 'dMRI_PA.nii.gz' \n",
    "    eroi.run()\n",
    "    pe_PA_1 = abspath('dMRI_PA.nii.gz')\n",
    "        \n",
    "    me = Merge()\n",
    "    me.inputs.in_files = [pe_AP_1,pe_PA_1]\n",
    "    me.inputs.dimension='t'\n",
    "    me.inputs.merged_file = 'merged_pes.nii.gz'\n",
    "    me.run()\n",
    "    \n",
    "    merged_pes = abspath('merged_pes.nii.gz')\n",
    "    \n",
    "    bvec = pe0.replace('.nii.gz','.voxel_space.bvecs')\n",
    "    bval = pe0.replace('.nii.gz','.bvals')\n",
    "    \n",
    "    return(merged_pes, pe0, bvec, bval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all dMRI sequences\n",
    "selectdmri=Node(Function(input_names=['seqname','studypath','subjid'],\n",
    "                         output_names=['nii_file','bvec','bval'], \n",
    "                         function=cvt_dicom),\n",
    "                name='selectdmri')\n",
    "selectdmri.inputs.studypath = raw_dir\n",
    "selectdmri.iterables = ('seqname',['dMRI_dir98_AP_14','dMRI_dir98_PA_14'])\n",
    "\n",
    "# Sort the files for unwarping\n",
    "sort_pe_list = JoinNode(Function(input_names=['pes'],\n",
    "                                 output_names=['merged_pes','pe0','bvec','bval'],\n",
    "                                 function=sort_pes), \n",
    "                        name='sort_pe_list', joinsource='selectdmri', joinfield='pes')\n",
    "\n",
    "# actually do the unwarping\n",
    "topup = Node(TOPUP(encoding_file=phase_encoding_file), name='topup')\n",
    "\n",
    "apply_topup = Node(ApplyTOPUP(in_index=[1], encoding_file=phase_encoding_file,\n",
    "                              method='jac', out_corrected='dmri_unwarped.nii.gz'),\n",
    "                   name='apply_topup')\n",
    "\n",
    "# reorient unwarped image to MNI space standard\n",
    "reorientdmri = Node(Reorient2Std(terminal_output='file'),\n",
    "                    name='reorientdmri')\n",
    "\n",
    "# average dMRI so we can make a mask\n",
    "avg_dmri = Node(MeanImage(), name='avg_dmri')\n",
    "\n",
    "# create a dMRI space brain mask using BET\n",
    "make_mask = Node(BET(mask=True), name='make_mask')\n",
    "\n",
    "# Eddy correction\n",
    "eddy = Node(Eddy(use_cuda=False, in_index=eddy_index_file, \n",
    "                 in_acqp=phase_encoding_file), name='eddy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepreprocflow = Workflow(name='prepreprocflow')\n",
    "prepreprocflow.connect([(infosource,selectdmri, [('subjid','subjid')]),\n",
    "                        (selectdmri,sort_pe_list, [('nii_file','pes'),\n",
    "                                                   ('bvec','bvecs'),\n",
    "                                                   ('bval','bvals')]),\n",
    "                        (sort_pe_list,topup, [('merged_pes','in_file')]),\n",
    "                        (topup, apply_topup, [('out_fieldcoef','in_topup_fieldcoef'), \n",
    "                                              ('out_movpar','in_topup_movpar')]),\n",
    "                        (sort_pe_list, apply_topup, [('pe0','in_files')]),\n",
    "                        (apply_topup, reorientdmri, [('out_corrected','in_file')]),\n",
    "                        (reorientdmri, avg_dmri, [('out_file','in_file')]),\n",
    "                        (avg_dmri, make_mask, [('out_file','in_file')]),\n",
    "                        (make_mask, datasink, [('mask_file','in_mask')]),\n",
    "                        #(reorientdmri, eddy, [('out_file','in_file')]),\n",
    "                        (sort_pe_list, datasink, [('bvec','in_bvec'),\n",
    "                                              ('bval','in_bval')]),\n",
    "                        #(topup, eddy, [('out_movpar','in_topup_movpar'),\n",
    "                        #               ('out_fieldcoef','in_topup_fieldcoef')]),\n",
    "                        #(eddy, datasink, [('out_rotated_bvecs','rotated_bvecs'),\n",
    "                        #                  ('out_parameter','field_and_movement_params'),\n",
    "                        #                  ('out_corrected','eddy_corrected_dmri'),\n",
    "                        #                  ('out_restricted_movement_rms','dmri_motion')]),\n",
    "                        (reorientdmri, datasink, [('out_file','unwarped_funcs')])\n",
    "                       ])\n",
    "\n",
    "prepreprocflow.base_dir = workflow_dir\n",
    "prepreprocflow.write_graph(graph2use='flat')\n",
    "prepreprocflow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Workflow\n",
    "\n",
    "This workflow performs the following steps:\n",
    "* coregistration between dMRI and T1w anat\n",
    "* registration to sample-specific template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_ToM(dtk_nii):\n",
    "    from nipype import logging, config\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from numpy import zeros_like\n",
    "    from os.path import abspath\n",
    "    \n",
    "    # r precuneus, l precuneus, r supramarginal, l supramarginal, r IPL, l IPL, l rostral-anterior cing, r rostral-anterior cing, l mofc, r mofc\n",
    "    labels = [2025,1025,2031,1031,2008,1008,2026,1026,2014,1014] \n",
    "    \n",
    "    aparc_nii = load(dtk_nii)\n",
    "    aparc_data = aparc_nii.get_data()\n",
    "    \n",
    "    ToM_data = zeros_like(aseg_data) \n",
    "    for x in labels:\n",
    "        ToM_data[aparc_data == x] = x\n",
    "    ToM_nifti = Nifti1Image(ToM_data, aparc_nii.affine)\n",
    "    save(ToM_nifti, 'ToM_rois.nii.gz')\n",
    "    ToM_file = abspath('ToM_rois.nii.gz')\n",
    "    \n",
    "    return(ToM_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nodes for creating ROI volumes from freesurfer segmentation\n",
    "file_template = {'dMRI': output_dir + '/unwarped_funcs/{subjid}/dmri_unwarped_reoriented.nii.gz'}\n",
    "selectfiles = Node(SelectFiles(file_template),name='selectfiles')\n",
    "\n",
    "# trim to B0 volume\n",
    "trim_b0 = Node(ExtractROI(t_min=0, t_size=1), name='trim_b0')\n",
    "\n",
    "# convert anat to nifti\n",
    "t1_to_nii = Node(MRIConvert(out_file='T1w.nii.gz',out_type='niigz'),\n",
    "                 name='t1_to_nii')\n",
    "# reorient anat\n",
    "reorient_t1 = Node(Reorient2Std(terminal_output='file'),\n",
    "                    name='reorient_t1')\n",
    "\n",
    "#convert parc to nifti\n",
    "parc_to_nii = Node(MRIConvert(out_file='aparcDTK.nii.gz',out_type='niigz'),\n",
    "                   name='parc_to_nii')\n",
    "\n",
    "#reorient parc\n",
    "reorient_parc = Node(Reorient2Std(terminal_output='file'),\n",
    "                     name='reorient_parc')\n",
    "\n",
    "# register anat to B0\n",
    "coreg_t1_b0 = Node(FLIRT(out_file='warp_t1.nii.gz',out_matrix_file='xfm.mat'), name='coreg_t1_b0')\n",
    "\n",
    "# apply registration to DK parcellation\n",
    "apply_reg = Node(FLIRT(out_file='warp_dtk.nii.gz',apply_xfm=True), name='apply_reg')\n",
    "\n",
    "# strip down to mentalizing network ROIs\n",
    "create_ToM_ROIs = Node(Function(input_names= ['dtk_nii'], output_names=['ToM_file'],name=isolate_ToM), \n",
    "                       name='create_ToM_ROIs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roiprocflow = Workflow(name='roiprocflow')\n",
    "roiprocflow.connect([(infosource, fsid, [('subjid','subjid')]), \n",
    "                     (fsid, fssource, [('fs_id','subject_id')]), \n",
    "                     (fssource, t1_to_nii, [('brain', 'in_file')]),\n",
    "                     (t1_to_nii, reorient_t1, [('out_file','in_file')]),\n",
    "                     (reorient_t1, coreg_t1_b0, [('out_file','in_file')]),\n",
    "                     \n",
    "                     (fssource, parc_to_nii, [('aparc_aseg', 'in_file')]),\n",
    "                     (parc_to_nii, reorient_parc, [('out_file','in_file')]),\n",
    "                     (reorient_parc, apply_reg, [('out_file','in_file')]),\n",
    "                     (coreg_t1_b0, apply_reg, [('out_matrix_file','in_matrix_file')]),\n",
    "                     \n",
    "                     (infosource, selectfiles, [('subjid','subjid')]),\n",
    "                     (selectfiles, trim_b0, [('dMRI','in_file')]),\n",
    "                     (trim_b0, coreg_t1_b0, [('roi_file','reference')]),\n",
    "                     (trim_b0, apply_reg, [('roi_file','reference')]),\n",
    "                     (apply_reg, create_ToM_ROIs, [('out_file','dtk_nii')]),\n",
    "                     \n",
    "                     (apply_reg, datasink, [('out_file','warped_DTK')]),\n",
    "                     (coreg_t1_b0, datasink, [('out_file','warped_T1')]),\n",
    "                     (trim_b0, datasink, [('roi_file','B0_vol_files')]),\n",
    "                     (create_ToM_ROIs, [('ToM_file','ToM_ROIs')])\n",
    "                    ])\n",
    "roiprocflow.base_dir = workflow_dir\n",
    "roiprocflow.write_graph(graph2use='flat')\n",
    "roiprocflow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':10})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
